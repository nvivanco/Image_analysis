{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e93121d-5a24-490b-9b22-ff154eaca611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing,GCNConv, global_mean_pool\n",
    "from torch_geometric.utils import degree # For potentially normalizing attention\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import add_self_loops, negative_sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import find_contours\n",
    "from skimage.draw import polygon\n",
    "from matplotlib.collections import LineCollection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a855aa7c-e982-467e-86b3-8f6ce66872bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'DUMM_giTG69_Glucose_013025'\n",
    "all_cells_filename = f'/Users/noravivancogonzalez/Documents/DuMM_image_analysis/all_cell_data_{folder}.pkl'\n",
    "all_cells_pd = pd.read_pickle(all_cells_filename)\n",
    "FOV = '007'\n",
    "trench_id = '295'\n",
    "df = all_cells_pd[(all_cells_pd['FOV'] == FOV) & (all_cells_pd['trench_id'] == trench_id)].copy()\n",
    "df['track_id'] = df['track_id'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90581be1-1fa8-440f-882d-b8000a83d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for fov 007 and trench id 295\n",
    "# manually correcting lineages id from track id\n",
    "ground_truth_lineage_id_dict = {'7': 'A',\n",
    "                                '25':'A.1',\n",
    "                                '46':'A.1',\n",
    "                                '67':'A.1',\n",
    "                                '73':'A.1.1',\n",
    "                                '79':'A.1.1',\n",
    "                                '97':'A.1.1',\n",
    "                                '102':'A.1.1',\n",
    "                                '108':'A.1.1',\n",
    "                                '115':'A.1.1',\n",
    "                                '119':'A.1.1',\n",
    "                                '124':'A.1.1',\n",
    "                                '130':'A.1.1',\n",
    "                                '132':'A.1.1',\n",
    "                                '135':'A.1.1',\n",
    "                                '140':'A.1.1',\n",
    "                                '142':'A.1.1',\n",
    "                                '143':'A.1.1.1',\n",
    "                                '151':'A.1.1.1',\n",
    "                                '154':'A.1.1.1',\n",
    "                                '159':'A.1.1.1',\n",
    "                                '163':'A.1.1.1',\n",
    "                                '167':'A.1.1.1',\n",
    "                                '172':'A.1.1.1',\n",
    "                                '178':'A.1.1.1',\n",
    "                                '183':'A.1.1.1',\n",
    "                                '144':'A.1.1.2',\n",
    "                                '152':'A.1.1.2',\n",
    "                                '155':'A.1.1.2',\n",
    "                                '160':'A.1.1.2',\n",
    "                                '164':'A.1.1.2',\n",
    "                                '168':'A.1.1.2',\n",
    "                                '173':'A.1.1.2',\n",
    "                                '179':'A.1.1.2',\n",
    "                                '184':'A.1.1.2',\n",
    "                                '187':'A.1.1.2',\n",
    "                                '191':'A.1.1.2',\n",
    "                                '196':'A.1.1.2',\n",
    "                                '202':'A.1.1.2',\n",
    "                                '74':'A.1.2',\n",
    "                                '80':'A.1.2',\n",
    "                                '93':'A.1.2',\n",
    "                                '109':'A.1.2',\n",
    "                                '120':'A.1.2',\n",
    "                                '125':'A.1.2',\n",
    "                                '131':'A.1.2',\n",
    "                                '133':'A.1.2',\n",
    "                                '136':'A.1.2',\n",
    "                                '141':'A.1.2',\n",
    "                                '145':'A.1.2.1',\n",
    "                                '150':'A.1.2.1',\n",
    "                                '156':'A.1.2.1',\n",
    "                                '161':'A.1.2.1',\n",
    "                                '169':'A.1.2.1',\n",
    "                                '174':'A.1.2.1',\n",
    "                                '180':'A.1.2.1',\n",
    "                                '188':'A.1.2.1',\n",
    "                                '192':'A.1.2.1',\n",
    "                                '197':'A.1.2.1',\n",
    "                                '203':'A.1.2.1',\n",
    "                                '208':'A.1.2.1',\n",
    "                                '213':'A.1.2.1',\n",
    "                                '146':'A.1.2.2',\n",
    "                                '162':'A.1.2.2',\n",
    "                                '165':'A.1.2.2',\n",
    "                                '170':'A.1.2.2',\n",
    "                                '175':'A.1.2.2',\n",
    "                                '181':'A.1.2.2',\n",
    "                                '193':'A.1.2.2',\n",
    "                                '198':'A.1.2.2',\n",
    "                                '204':'A.1.2.2',\n",
    "                                '209':'A.1.2.2',\n",
    "                                '216':'A.1.2.2',\n",
    "                                '222':'A.1.2.2',\n",
    "                                '74':'A.1.2',\n",
    "                                '19': 'A.2',\n",
    "                                '81': 'A.2.1',\n",
    "                                '88':'A.2.1',\n",
    "                                '94':'A.2.1',\n",
    "                                '137':'A.2.1',\n",
    "                                '147':'A.2.1.1',\n",
    "                                '166':'A.2.1.1',\n",
    "                                '176':'A.2.1.1',\n",
    "                                '182':'A.2.1.1',\n",
    "                                '189':'A.2.1.1',\n",
    "                                '194':'A.2.1.1',\n",
    "                                '199':'A.2.1.1',\n",
    "                                '205':'A.2.1.1',\n",
    "                                '210':'A.2.1.1',\n",
    "                                '217':'A.2.1.1',\n",
    "                                '223':'A.2.1.1',\n",
    "                                '229':'A.2.1.1',\n",
    "                                '234':'A.2.1.1',\n",
    "                                '148':'A.2.1.2',\n",
    "                                '157':'A.2.1.2',\n",
    "                                '177':'A.2.1.2',\n",
    "                                '195':'A.2.1.2',\n",
    "                                '206':'A.2.1.2',\n",
    "                                '211':'A.2.1.2',\n",
    "                                '214':'A.2.1.2',\n",
    "                                '218':'A.2.1.2',\n",
    "                                '224':'A.2.1.2.1',\n",
    "                                '230':'A.2.1.2.1',\n",
    "                                '235':'A.2.1.2.1',\n",
    "                                '240':'A.2.1.2.1',\n",
    "                                '245':'A.2.1.2.1',\n",
    "                                '249':'A.2.1.2.1',\n",
    "                                '225':'A.2.1.2.2',\n",
    "                                '82': 'A.2.2',\n",
    "                                '138':'A.2.2.1',\n",
    "                                '158':'A.2.2.1',\n",
    "                                '171':'A.2.2.1',\n",
    "                                '190':'A.2.2.1',\n",
    "                                '207':'A.2.2.1',\n",
    "                                '212':'A.2.2.1',\n",
    "                                '220':'A.2.2.1',\n",
    "                                '227':'A.2.2.1',\n",
    "                                '232':'A.2.2.1',\n",
    "                                '238':'A.2.2.1',\n",
    "                                '243':'A.2.2.1',\n",
    "                                '247':'A.2.2.1',\n",
    "                                '255':'A.2.2.1',\n",
    "                                '258':'A.2.2.1',\n",
    "                                '262':'A.2.2.1',\n",
    "                                '264':'A.2.2.1',\n",
    "                                '267':'A.2.2.1.1',\n",
    "                                '268':'A.2.2.1.2',\n",
    "                                '139':'A.2.2.2',\n",
    "                                '200': 'A.2.2.2.1',\n",
    "                                '215': 'A.2.2.2.1',\n",
    "                                '221': 'A.2.2.2.1',\n",
    "                                '228': 'A.2.2.2.1',\n",
    "                                '233': 'A.2.2.2.1',\n",
    "                                '239': 'A.2.2.2.1',\n",
    "                                '244': 'A.2.2.2.1',\n",
    "                                '248': 'A.2.2.2.1',\n",
    "                                '252': 'A.2.2.2.1',\n",
    "                                '256': 'A.2.2.2.1',\n",
    "                                '259': 'A.2.2.2.1',\n",
    "                                '263': 'A.2.2.2.1',\n",
    "                                '265': 'A.2.2.2.1',\n",
    "                                '266': 'A.2.2.2.1',\n",
    "                                '269': 'A.2.2.2.1',\n",
    "                                '272': 'A.2.2.2.1',\n",
    "                                '274': 'A.2.2.2.1',\n",
    "                                '201': 'A.2.2.2.2',\n",
    "                                '273': 'A.2.2.2.2',\n",
    "                                '277': 'A.2.2.2.2',\n",
    "                                '278': 'A.2.2.2.2.1',\n",
    "                                '280': 'A.2.2.2.2.1',\n",
    "                                '281': 'A.2.2.2.2.1',\n",
    "                                '282': 'A.2.2.2.2.1',\n",
    "                                '283': 'A.2.2.2.2.1',\n",
    "                                '284': 'A.2.2.2.2.1',\n",
    "                                '285': 'A.2.2.2.2.1',\n",
    "                                '286': 'A.2.2.2.2.1',\n",
    "                                '287': 'A.2.2.2.2.1.1',\n",
    "                                '288': 'A.2.2.2.2.1.2',\n",
    "                                '279': 'A.2.2.2.2.2',\n",
    "                                '289': 'A.2.2.2.2.1',\n",
    "                                '291': 'A.2.2.2.2.1',\n",
    "                                '292': 'A.2.2.2.2.1',\n",
    "                                '293': 'A.2.2.2.2.1',\n",
    "                                '294': 'A.2.2.2.2.1',\n",
    "                                '295': 'A.2.2.2.2.1',\n",
    "                                '296': 'A.2.2.2.2.1',\n",
    "                                '297': 'A.2.2.2.2.1',\n",
    "                                '298': 'A.2.2.2.2.1',\n",
    "                                '290': 'A.2.2.2.2.2.2',\n",
    "                                '299': 'A.2.2.2.2.2.2',\n",
    "                                '300': 'A.2.2.2.2.2.2',\n",
    "                                '301': 'A.2.2.2.2.2.2',\n",
    "                                '302': 'A.2.2.2.2.2.2.1',\n",
    "                                '304': 'A.2.2.2.2.2.2.1',\n",
    "                                '305': 'A.2.2.2.2.2.2.1',\n",
    "                                '306': 'A.2.2.2.2.2.2.1',\n",
    "                                '307': 'A.2.2.2.2.2.2.1',\n",
    "                                '308': 'A.2.2.2.2.2.2.1',\n",
    "                                '309': 'A.2.2.2.2.2.2.1',\n",
    "                                '303': 'A.2.2.2.2.2.2.2',\n",
    "                                '310': 'A.2.2.2.2.2.2.2',\n",
    "                                '311': 'A.2.2.2.2.2.2.2',\n",
    "                                '312': 'A.2.2.2.2.2.2.2',\n",
    "                                '313': 'A.2.2.2.2.2.2.2.1',\n",
    "                                '315': 'A.2.2.2.2.2.2.2.1',\n",
    "                                '316': 'A.2.2.2.2.2.2.2.1',\n",
    "                                '317': 'A.2.2.2.2.2.2.2.1',\n",
    "                                '318': 'A.2.2.2.2.2.2.2.1',\n",
    "                                '319': 'A.2.2.2.2.2.2.2.1',\n",
    "                                '320': 'A.2.2.2.2.2.2.2.1',\n",
    "                                '314': 'A.2.2.2.2.2.2.2.2',\n",
    "                                '321': 'A.2.2.2.2.2.2.2.2',\n",
    "                                '322': 'A.2.2.2.2.2.2.2.2',\n",
    "                                '323': 'A.2.2.2.2.2.2.2.2',\n",
    "                                '324': 'A.2.2.2.2.2.2.2.2',\n",
    "                                '325': 'A.2.2.2.2.2.2.2.2',\n",
    "                                '326': 'A.2.2.2.2.2.2.2.2',\n",
    "                                '327': 'A.2.2.2.2.2.2.2.2.1',\n",
    "                                '329': 'A.2.2.2.2.2.2.2.2.1',\n",
    "                                '330': 'A.2.2.2.2.2.2.2.2.1',\n",
    "                                '328': 'A.2.2.2.2.2.2.2.2.2',\n",
    "                                '331': 'A.2.2.2.2.2.2.2.2.2',\n",
    "                                '332': 'A.2.2.2.2.2.2.2.2.2.1',\n",
    "                                '333': 'A.2.2.2.2.2.2.2.2.2.2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c40d2b-fba8-4605-87df-11e6e2d94845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ground_truth_lineage'] = None\n",
    "df['ground_truth_lineage']= df['track_id'].map(ground_truth_lineage_id_dict)\n",
    "df.rename(columns = {'centroid-0': 'centroid_y','centroid-1': 'centroid_x'}, inplace = True)\n",
    "df_cells = df[df['ground_truth_lineage'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42dd95bf-2d24-4b67-a93b-b545f6096499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lineage IDs to unique integers as labels\n",
    "all_unique_lineages = sorted(df_cells['ground_truth_lineage'].unique())\n",
    "lineage_to_int_mapping = {lineage: i for i, lineage in enumerate(all_unique_lineages)}\n",
    "num_lineage_classes = len(all_unique_lineages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86fa565e-8032-4936-83bb-c60fbdd41bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hj/bk95lprn3zb88y7bqhjh9j5m0000gr/T/ipykernel_63404/1883193674.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cells['numeric_lineage'] = df_cells['ground_truth_lineage'].map(lineage_to_int_mapping)\n"
     ]
    }
   ],
   "source": [
    "df_cells['numeric_lineage'] = df_cells['ground_truth_lineage'].map(lineage_to_int_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75fe617b-e3ab-4a38-872d-d3a894fee8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ad92ca-0206-4bc3-8c80-f92577486427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hj/bk95lprn3zb88y7bqhjh9j5m0000gr/T/ipykernel_63404/157364811.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cells['node_id'] = df_cells.index # Assign unique global node ID\n"
     ]
    }
   ],
   "source": [
    "df_cells['node_id'] = df_cells.index # Assign unique global node ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee66941d-0193-4d8a-8e62-23a14c0914f1",
   "metadata": {},
   "source": [
    "# try architecture like https://link.springer.com/chapter/10.1007/978-3-031-19803-8_36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6117cb9-3885-4617-ac9c-44931239a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function expects a sub-DataFrame already filtered for a specific lineage branch\n",
    "def create_lineage_graph(df_lineage, device='cpu'):\n",
    "    original_global_node_ids = df_lineage['node_id'].values\n",
    "    global_id_to_local_idx = {global_id: i for i, global_id in enumerate(original_global_node_ids)}\n",
    "\n",
    "    x = torch.tensor(df_lineage[node_feature_cols].to_numpy(dtype=np.float32), dtype=torch.float).to(device)\n",
    "    \n",
    "    y = torch.tensor(df_lineage['numeric_lineage'].values, dtype=torch.long).to(device)\n",
    "    # Ensure pos is 2D if you have both x and y, or handle 1D appropriately in negative sampling\n",
    "    # If your 'pos' is just centroid_y, then it's [num_nodes]. Need to reshape to [num_nodes, 1]\n",
    "    # for consistent tensor operations.\n",
    "    pos = torch.tensor(df_lineage['centroid_y'].values, dtype=torch.float).to(device)\n",
    "    if pos.dim() == 1: # Reshape if it's just a 1D tensor of y-coords\n",
    "        pos = pos.unsqueeze(1) # Makes it [num_nodes, 1]\n",
    "\n",
    "    node_time_frames = torch.tensor(df_lineage['time_frame'].values, dtype=torch.long).to(device)\n",
    "\n",
    "    num_nodes = len(df_lineage)\n",
    "    if num_nodes == 0:\n",
    "        return None\n",
    "\n",
    "    source_nodes_local_idx = []\n",
    "    target_nodes_local_idx = []\n",
    "\n",
    "    sorted_time_frames = sorted(df_lineage['time_frame'].unique())\n",
    "\n",
    "    # This loop builds the lists of source_nodes_local_idx and target_nodes_local_idx\n",
    "    for i in range(len(sorted_time_frames) - 1):\n",
    "        current_t = sorted_time_frames[i]\n",
    "        next_t = sorted_time_frames[i+1]\n",
    "\n",
    "        df_current_t = df_lineage[df_lineage['time_frame'] == current_t]\n",
    "        df_next_t = df_lineage[df_lineage['time_frame'] == next_t]\n",
    "\n",
    "        current_lineage_to_node = df_current_t.set_index('ground_truth_lineage')['node_id'].to_dict()\n",
    "        next_lineage_to_node = df_next_t.set_index('ground_truth_lineage')['node_id'].to_dict()\n",
    "\n",
    "        for idx, row in df_current_t.iterrows():\n",
    "            current_global_node_id = row['node_id']\n",
    "            current_ground_truth_lineage = row['ground_truth_lineage']\n",
    "\n",
    "            if current_ground_truth_lineage in next_lineage_to_node:\n",
    "                next_global_node_id = next_lineage_to_node[current_ground_truth_lineage]\n",
    "                source_nodes_local_idx.append(global_id_to_local_idx[current_global_node_id])\n",
    "                target_nodes_local_idx.append(global_id_to_local_idx[next_global_node_id])\n",
    "\n",
    "            daughter1_lineage = f\"{current_ground_truth_lineage}.1\"\n",
    "            daughter2_lineage = f\"{current_ground_truth_lineage}.2\"\n",
    "\n",
    "            if daughter1_lineage in next_lineage_to_node:\n",
    "                next_global_node_id = next_lineage_to_node[daughter1_lineage]\n",
    "                source_nodes_local_idx.append(global_id_to_local_idx[current_global_node_id])\n",
    "                target_nodes_local_idx.append(global_id_to_local_idx[next_global_node_id])\n",
    "            if daughter2_lineage in next_lineage_to_node:\n",
    "                next_global_node_id = next_lineage_to_node[daughter2_lineage]\n",
    "                source_nodes_local_idx.append(global_id_to_local_idx[current_global_node_id])\n",
    "                target_nodes_local_idx.append(global_id_to_local_idx[next_global_node_id])\n",
    "\n",
    "    # --- Determine edge_index based on collected source/target lists ---\n",
    "    if not source_nodes_local_idx: # Case: No edges found at all for this lineage branch\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long).to(device)\n",
    "        # For this case, initial_edge_attr must also be an empty tensor\n",
    "        initial_edge_attr = torch.empty((0, len(node_feature_cols) + 1), dtype=torch.float).to(device)\n",
    "    else: # Case: Some potential edges were found\n",
    "        unique_edges = list(set(zip(source_nodes_local_idx, target_nodes_local_idx)))\n",
    "        if not unique_edges: # This should theoretically be covered by the first 'if', but acts as a safeguard\n",
    "            edge_index = torch.empty((2, 0), dtype=torch.long).to(device)\n",
    "            initial_edge_attr = torch.empty((0, len(node_feature_cols) + 1), dtype=torch.float).to(device)\n",
    "        else: # Case: Non-empty, unique edges exist\n",
    "            source_nodes_unique, target_nodes_unique = zip(*unique_edges)\n",
    "            edge_index = torch.tensor([list(source_nodes_unique), list(target_nodes_unique)], dtype=torch.long).to(device)\n",
    "\n",
    "            # --- ONLY in this 'else' block, calculate initial_edge_attr for the actual edges ---\n",
    "            # Get node features for source and target nodes of the created edges\n",
    "            # (Use df_lineage.iloc with the numpy conversion of edge_index for correct indexing)\n",
    "            true_src_node_dfs = df_lineage.iloc[edge_index[0].cpu().numpy()]\n",
    "            true_tgt_node_dfs = df_lineage.iloc[edge_index[1].cpu().numpy()]\n",
    "\n",
    "            initial_edge_features_list = []\n",
    "            for i in range(edge_index.size(1)): # Iterate over the actual unique edges\n",
    "                # Use original node features for initial D-S block\n",
    "\n",
    "                v_i_raw = torch.tensor(true_src_node_dfs.iloc[i][node_feature_cols].to_numpy(dtype=np.float32), dtype=torch.float)\n",
    "                v_j_raw = torch.tensor(true_tgt_node_dfs.iloc[i][node_feature_cols].to_numpy(dtype=np.float32), dtype=torch.float)\n",
    "                initial_edge_features_list.append(DS_block(v_i_raw, v_j_raw))\n",
    "\n",
    "            initial_edge_attr = torch.stack(initial_edge_features_list, dim=0).to(device)\n",
    "            # No 'else' needed here, as this block only runs if initial_edge_features_list is guaranteed to be non-empty\n",
    "            # because edge_index.size(1) > 0.\n",
    "\n",
    "    data = Data(x=x,\n",
    "                edge_index=edge_index,\n",
    "                y=y,\n",
    "                pos=pos,\n",
    "                num_nodes=num_nodes,\n",
    "                time_frame=node_time_frames,\n",
    "                edge_attr=initial_edge_attr, # This will now always be a correctly shaped tensor\n",
    "                root_lineage_branch=df_lineage['ground_truth_lineage'].iloc[0],\n",
    "                start_time_frame=df_lineage['time_frame'].min(),\n",
    "                experiment_name=df_lineage['experiment_name'].iloc[0],\n",
    "                fov=df_lineage['FOV'].iloc[0],\n",
    "                trench_id=df_lineage['trench_id'].iloc[0]\n",
    "               )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e4ddc1a-ba9b-45e2-9015-4827986c57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_local_temporal_negative_samples(data: Data, num_neg_samples_per_pos_edge: float, radius_threshold: float, device='cpu'):\n",
    "    \"\"\"\n",
    "    Generates negative samples by considering only cells in consecutive time frames\n",
    "    and within a certain spatial radius of potential source nodes, excluding true positives.\n",
    "\n",
    "    Args:\n",
    "        data (torch_geometric.data.Data): A single graph batch containing x, edge_index, pos, time_frame.\n",
    "        num_neg_samples_per_pos_edge (float): Ratio of negative samples to positive samples.\n",
    "                                                e.g., 1.0 for 1:1, 2.0 for 2:1.\n",
    "        radius_threshold (float): Maximum spatial distance for a potential negative connection.\n",
    "        device (str): Device to put tensors on.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: edge_index of sampled negative connections, shape [2, num_neg_samples].\n",
    "    \"\"\"\n",
    "    if data.edge_index.numel() == 0: # No positive edges, no negative samples possible this way\n",
    "        return torch.empty((2, 0), dtype=torch.long, device=device)\n",
    "\n",
    "    # Convert tensors to CPU for easier numpy/list processing if needed, then back to device\n",
    "    pos_coords = data.pos.cpu().numpy() # Assuming pos is [num_nodes, 2] (y,x) or [num_nodes, 1] (y)\n",
    "    time_frames = data.time_frame.cpu().numpy()\n",
    "    num_nodes = data.num_nodes\n",
    "    existing_edges = set(tuple(e) for e in data.edge_index.cpu().T.tolist()) # Convert to set for fast lookup\n",
    "\n",
    "    potential_neg_samples = []\n",
    "\n",
    "    # Iterate through all possible source nodes\n",
    "    for i in range(num_nodes):\n",
    "        current_node_time = time_frames[i]\n",
    "        current_node_pos = pos_coords[i]\n",
    "\n",
    "        # Iterate through all possible target nodes (j)\n",
    "        for j in range(num_nodes):\n",
    "            # 1. Temporal Constraint: Only consider next time frame\n",
    "            if time_frames[j] != current_node_time + 1:\n",
    "                continue\n",
    "\n",
    "            # 2. Local Constraint: Check spatial proximity (Euclidean distance)\n",
    "            target_node_pos = pos_coords[j]\n",
    "            # Adjust distance calculation based on your 'pos' dimension\n",
    "            if pos_coords.ndim == 1: # If 'pos' is just centroid_y (1D)\n",
    "                distance = np.abs(current_node_pos - target_node_pos)\n",
    "            else: # If 'pos' is (y, x) or (x, y) etc. (2D or more)\n",
    "                distance = np.linalg.norm(current_node_pos - target_node_pos)\n",
    "\n",
    "            if distance > radius_threshold:\n",
    "                continue\n",
    "\n",
    "            # 3. Exclude existing positive edges\n",
    "            if (i, j) not in existing_edges:\n",
    "                potential_neg_samples.append((i, j))\n",
    "\n",
    "    # Convert to tensor\n",
    "    if not potential_neg_samples:\n",
    "        return torch.empty((2, 0), dtype=torch.long, device=device), torch.empty((0, data.x.size(1) + 1), dtype=torch.float, device=device)\n",
    "\n",
    "    potential_neg_samples_tensor = torch.tensor(potential_neg_samples, dtype=torch.long).T.to(device)\n",
    "\n",
    "    # Sample a subset\n",
    "    num_positive_edges = data.edge_index.size(1)\n",
    "    desired_neg_samples = int(num_positive_edges * num_neg_samples_per_pos_edge)\n",
    "\n",
    "    if desired_neg_samples >= potential_neg_samples_tensor.size(1):\n",
    "        sampled_neg_edge_index = potential_neg_samples_tensor\n",
    "    else:\n",
    "        indices = torch.randperm(potential_neg_samples_tensor.size(1), device=device)[:desired_neg_samples]\n",
    "        sampled_neg_edge_index = potential_neg_samples_tensor[:, indices]\n",
    "\n",
    "    # Compute initial edge_attr for the sampled negative edges\n",
    "    neg_src_nodes_indices = sampled_neg_edge_index[0]\n",
    "    neg_tgt_nodes_indices = sampled_neg_edge_index[1]\n",
    "\n",
    "    initial_neg_edge_attr_list = []\n",
    "    for i in range(sampled_neg_edge_index.size(1)):\n",
    "        v_i_raw = data.x[neg_src_nodes_indices[i]] # Use original node features (data.x)\n",
    "        v_j_raw = data.x[neg_tgt_nodes_indices[i]]\n",
    "        initial_neg_edge_attr_list.append(DS_block(v_i_raw, v_j_raw))\n",
    "\n",
    "    if initial_neg_edge_attr_list:\n",
    "        initial_neg_edge_attr = torch.stack(initial_neg_edge_attr_list, dim=0).to(device)\n",
    "    else:\n",
    "        initial_neg_edge_attr = torch.empty((0, data.x.size(1) + 1), dtype=torch.float).to(device)\n",
    "\n",
    "    return sampled_neg_edge_index, initial_neg_edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b0927bca-9707-4c66-95d5-371c46f90bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper MLP for f_PDN_edge (Attention Weights) ---\n",
    "class PDNEdgeMLP(nn.Module):\n",
    "    def __init__(self, edge_feature_dim, out_dim=1):\n",
    "        super().__init__()\n",
    "        # Simplified MLP for attention weights (scalar output)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(edge_feature_dim, 32), # Example hidden dim\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, out_dim)\n",
    "        )\n",
    "    def forward(self, z): # z is edge feature\n",
    "        return self.mlp(z)\n",
    "\n",
    "# --- Helper MLP for f_PDN_node (Node Feature Transformation) ---\n",
    "class PDNNodeMLP(nn.Module):\n",
    "    def __init__(self, node_feature_dim, out_dim):\n",
    "        super().__init__()\n",
    "        # MLP for transforming node features before aggregation\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(node_feature_dim, out_dim), # Typically out_dim = node_feature_dim\n",
    "            nn.ReLU()\n",
    "            # No final ReLU if you want negative values for weighted sum, or add Batch Norm\n",
    "        )\n",
    "    def forward(self, x): # x is node feature\n",
    "        return self.mlp(x)\n",
    "\n",
    "# --- D-S Block (Distance & Similarity) ---\n",
    "def DS_block(v_i, v_j):\n",
    "    \"\"\"\n",
    "    Calculates Distance & Similarity vector for two node feature vectors.\n",
    "    Equivalent to Eq. 3 in the paper.\n",
    "    Args:\n",
    "        v_i (torch.Tensor): Feature vector of node i, shape [d_v].\n",
    "        v_j (torch.Tensor): Feature vector of node j, shape [d_v].\n",
    "    Returns:\n",
    "        torch.Tensor: Concatenated vector of absolute differences and cosine similarity, shape [d_v + 1].\n",
    "    \"\"\"\n",
    "    abs_diff = torch.abs(v_i - v_j)\n",
    "    cosine_similarity = F.cosine_similarity(v_i.unsqueeze(0), v_j.unsqueeze(0)).squeeze(0)\n",
    "    return torch.cat([abs_diff, cosine_similarity.unsqueeze(0)], dim=-1) # Unsqueeze for scalar cos_sim\n",
    "\n",
    "# --- The EP-MPNN Block ---\n",
    "class EP_MPNN_Block(MessagePassing):\n",
    "    def __init__(self, node_channels, edge_channels):\n",
    "        super().__init__(aggr='add', flow='source_to_target') # Aggregation for node update. source_to_target for N(i) being t-1 nodes.\n",
    "        self.node_channels = node_channels\n",
    "        self.edge_channels = edge_channels\n",
    "\n",
    "        # Node Feature Update components (PDN-Conv)\n",
    "        # f_PDN_edge: Maps edge features to scalar attention weights (omega)\n",
    "        self.f_pdn_edge = PDNEdgeMLP(edge_channels, out_dim=1)\n",
    "        # f_PDN_node: Transforms node features (tilde_x)\n",
    "        self.f_pdn_node = PDNNodeMLP(node_channels, node_channels) # Output dim same as input for residuals\n",
    "\n",
    "        # Edge Feature Update components (Edge Encoder)\n",
    "        # f_EE_edge: MLP to update edge features.\n",
    "        # Input: current edge_features (edge_channels)\n",
    "        #        + updated node_features from source (node_channels)\n",
    "        #        + updated node_features from target (node_channels)\n",
    "        #        + D-S block output (node_channels + 1)\n",
    "        self.f_ee_edge = nn.Sequential(\n",
    "            nn.Linear(edge_channels + 2 * node_channels + (node_channels + 1), 128), # Example hidden size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, edge_channels) # Output dim same as edge_channels\n",
    "        )\n",
    "\n",
    "        # BatchNorm (optional but often helpful for stability)\n",
    "        self.bn_node = nn.BatchNorm1d(node_channels)\n",
    "        self.bn_edge = nn.BatchNorm1d(edge_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x: node features X^(l-1)\n",
    "        # edge_index: graph connectivity\n",
    "        # edge_attr: edge features Z^(l-1)\n",
    "\n",
    "        # 1. Edge Feature Update (first for this block, as per paper's description \"In the l-th block vi = x(l)i and vj = x(l)j\")\n",
    "        # However, the paper implies x(l) is used. Let's assume for simplicity first block\n",
    "        # uses x(l-1) and subsequent blocks use x(l).\n",
    "        # To align with: \"In the l-th block vi = x(l)i and vj = x(l)j.\" and \"the features of an edge ej,i are updated based on the features of νi and νj\"\n",
    "        # This means edge update uses nodes *after* they are potentially updated by previous block.\n",
    "        # For l=0 (initial), x(0) are raw features. For l>0, x(l) comes from PDN-Conv.\n",
    "        # For simplicity, let's make it work sequentially: update nodes, THEN update edges using new nodes.\n",
    "        # Or, as paper implies \"alternately updated\", meaning within the block loop:\n",
    "        # Step A: Compute updated nodes x^(l) from x^(l-1) and z^(l-1)\n",
    "        # Step B: Compute updated edges z^(l) from x^(l) and z^(l-1)\n",
    "        # Let's follow this:\n",
    "\n",
    "        # Cache inputs for edge update after node update\n",
    "        x_prev = x\n",
    "        edge_attr_prev = edge_attr\n",
    "\n",
    "        # 2. Node Feature Update (PDN-Conv: Eq. 2)\n",
    "        # Message passing step\n",
    "        \n",
    "        x_updated = self.propagate(edge_index, x=x, edge_attr=edge_attr, size=(x.size(0), x.size(0)))\n",
    "\n",
    "        # Add residual connection and apply BatchNorm/ReLU\n",
    "        x = self.bn_node(x_prev + x_updated) # Residual (assuming input and output dims are same)\n",
    "        x = F.relu(x) # x is now X^(l)\n",
    "\n",
    "        # 3. Edge Feature Update (Edge Encoder: based on x^(l) and z^(l-1))\n",
    "        # Get source and target node embeddings for edges\n",
    "        row, col = edge_index\n",
    "        src_node_features = x[row] # x^(l) for source nodes\n",
    "        tgt_node_features = x[col] # x^(l) for target nodes\n",
    "\n",
    "        # Compute D-S block output for each edge\n",
    "        ds_outputs = []\n",
    "        for i in range(edge_attr.size(0)): # Iterate per edge\n",
    "            ds_outputs.append(DS_block(src_node_features[i], tgt_node_features[i]))\n",
    "        ds_outputs_tensor = torch.stack(ds_outputs, dim=0) # Shape: [num_edges, node_channels + 1]\n",
    "\n",
    "        # Concatenate inputs for f_EE_edge\n",
    "        # current edge_features (Z^(l-1))\n",
    "        # updated node_features from source (X^(l))\n",
    "        # updated node_features from target (X^(l))\n",
    "        # D-S block output (from X^(l), X^(l))\n",
    "        edge_input_for_mlp = torch.cat([\n",
    "            edge_attr_prev, # Z^(l-1)\n",
    "            src_node_features, # X^(l)\n",
    "            tgt_node_features, # X^(l)\n",
    "            ds_outputs_tensor # D-S block on X^(l)\n",
    "        ], dim=-1)\n",
    "\n",
    "        # Pass through edge encoder MLP\n",
    "        edge_attr = self.f_ee_edge(edge_input_for_mlp) # Z^(l)\n",
    "        edge_attr = self.bn_edge(edge_attr) # BatchNorm\n",
    "        edge_attr = F.relu(edge_attr) # ReLU\n",
    "\n",
    "        return x, edge_attr # Return updated nodes (X^(l)) and updated edges (Z^(l))\n",
    "\n",
    "    def message(self, x_j, edge_attr): # x_j is neighbor features, edge_attr_i is edge features to neighbor\n",
    "        # x_j: x^(l-1)_j (features of neighbor j)\n",
    "        # edge_attr: z^(l-1)_ji (features of edge (j,i))\n",
    "        # Compute omega_ji = f_PDN_edge(z_ji) (attention weight for edge j,i)\n",
    "        omega_ji = self.f_pdn_edge(edge_attr)\n",
    "        # Compute tilde_x_j = f_PDN_node(x_j) (mapped feature vector of node j)\n",
    "        tilde_x_j = self.f_pdn_node(x_j)\n",
    "\n",
    "        # The message is omega_ji * tilde_x_j\n",
    "        return omega_ji * tilde_x_j\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size=None):\n",
    "        # inputs: [num_messages, hidden_channels] (omega_ji * tilde_x_j for each edge)\n",
    "        # index: target node index for each message\n",
    "        # dim_size: total number of nodes\n",
    "        # Summation aggregation (as per Eq. 2)\n",
    "        out = super().aggregate(inputs, index, dim_size=dim_size)\n",
    "        return out\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # This is where the output of aggregation (sum_j omega_ji * tilde_x_j)\n",
    "        # is combined with the current node feature.\n",
    "        # But per Eq. 2, the residual is handled in the forward pass.\n",
    "        # So we just return the aggregated messages here.\n",
    "        return aggr_out # This will be the x_updated in the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e88afc7e-4b1d-4db9-9f1c-80d9f1709672",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineageLinkPredictionGNN(nn.Module):\n",
    "    def __init__(self, in_channels, initial_edge_channels, hidden_channels, num_blocks=2):\n",
    "        super().__init__()\n",
    "        self.num_blocks = num_blocks\n",
    "        self.hidden_channels = hidden_channels\n",
    "\n",
    "        # Initial Linear layer to project input features to hidden_channels\n",
    "        self.initial_node_proj = nn.Linear(in_channels, hidden_channels)\n",
    "\n",
    "        # Initial Edge Feature Projector (optional, if initial_edge_channels is different from hidden_channels)\n",
    "        # Or you can define specific initial edge features.\n",
    "        self.initial_edge_proj = nn.Linear(initial_edge_channels, hidden_channels)\n",
    "\n",
    "        # Stack L EP-MPNN blocks\n",
    "        self.ep_mpnn_blocks = nn.ModuleList()\n",
    "        for _ in range(num_blocks):\n",
    "            self.ep_mpnn_blocks.append(EP_MPNN_Block(hidden_channels, hidden_channels))\n",
    "\n",
    "        # Decoder for link prediction (takes concatenated node embeddings)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_channels, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1) # Output a single logit for binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr # Data now also has edge_attr\n",
    "\n",
    "        # Initial projection of node features\n",
    "        x = F.relu(self.initial_node_proj(x))\n",
    "\n",
    "        # Initial projection of edge features\n",
    "        edge_attr = F.relu(self.initial_edge_proj(edge_attr)) # Ensure initial_edge_channels maps to hidden_channels\n",
    "\n",
    "        # Pass through L EP-MPNN blocks\n",
    "        for block in self.ep_mpnn_blocks:\n",
    "            x, edge_attr = block(x, edge_index, edge_attr) # Both nodes and edges get updated\n",
    "\n",
    "        # x are the final node embeddings after L blocks\n",
    "        return x # Return node embeddings for the decoder\n",
    "\n",
    "    def decode(self, z, pos_edge_index, neg_edge_index=None):\n",
    "        # This decode method remains largely the same as before,\n",
    "        # as it operates on the final node embeddings 'z'.\n",
    "        edge_indices = torch.cat([pos_edge_index, neg_edge_index], dim=-1) if neg_edge_index is not None else pos_edge_index\n",
    "\n",
    "        src_embed = z[edge_indices[0]]\n",
    "        tgt_embed = z[edge_indices[1]]\n",
    "        edge_features = torch.cat([src_embed, tgt_embed], dim=-1) # Concatenate\n",
    "\n",
    "        logits = self.decoder(edge_features).squeeze(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "613d3dd1-deef-450b-abb2-5b3df8cd1cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_link_prediction(model, train_loader, optimizer, criterion, device, neg_sample_ratio=1.0, radius_threshold=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        neg_edge_index, neg_edge_attr_initial = generate_local_temporal_negative_samples(\n",
    "            data,\n",
    "            num_neg_samples_per_pos_edge=neg_sample_ratio,\n",
    "            radius_threshold=radius_threshold,\n",
    "            device=device\n",
    "        )\n",
    "        if neg_edge_index.numel() == 0:\n",
    "            print(\"Warning: No negative samples generated for a batch. Skipping.\")\n",
    "            continue # Skip this batch if no valid negative samples\n",
    "\n",
    "        z = model(data) # Forward pass returns final node embeddings\n",
    "\n",
    "        pos_logits = model.decode(z, data.edge_index)\n",
    "        neg_logits = model.decode(z, neg_edge_index)\n",
    "\n",
    "        pos_labels = torch.ones(pos_logits.size(0), device=device)\n",
    "        neg_labels = torch.zeros(neg_logits.size(0), device=device)\n",
    "\n",
    "        logits = torch.cat([pos_logits, neg_logits])\n",
    "        labels = torch.cat([pos_labels, neg_labels])\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "def evaluate_link_prediction(model, loader, criterion, device, neg_sample_ratio=1.0, radius_threshold=None):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "\n",
    "            # Generate negative edges for evaluation\n",
    "            neg_edge_index, neg_edge_attr_initial = generate_local_temporal_negative_samples(\n",
    "                data,\n",
    "                num_neg_samples_per_pos_edge=neg_sample_ratio,\n",
    "                radius_threshold=radius_threshold,\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "            if neg_edge_index.numel() == 0:\n",
    "                print(\"Warning: No negative samples generated for a batch during evaluation. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Combine positive and negative edges for the GNN's forward pass\n",
    "            combined_edge_index = torch.cat([data.edge_index, neg_edge_index], dim=1)\n",
    "            combined_edge_attr_initial = torch.cat([data.edge_attr, neg_edge_attr_initial], dim=0)\n",
    "\n",
    "            temp_data_for_forward = data.clone()\n",
    "            temp_data_for_forward.edge_index = combined_edge_index\n",
    "            temp_data_for_forward.edge_attr = combined_edge_attr_initial\n",
    "\n",
    "            z = model(temp_data_for_forward) # Pass the combined data for message passing\n",
    "\n",
    "            pos_logits = model.decode(z, data.edge_index)\n",
    "            neg_logits = model.decode(z, neg_edge_index)\n",
    "\n",
    "            pos_labels = torch.ones(pos_logits.size(0), device=device)\n",
    "            neg_labels = torch.zeros(neg_logits.size(0), device=device)\n",
    "\n",
    "            logits = torch.cat([pos_logits, neg_logits])\n",
    "            labels = torch.cat([pos_labels, neg_labels])\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = (torch.sigmoid(logits) > 0.5).long() # Convert logits to binary predictions\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "    # You might also want to calculate precision, recall, F1-score for link prediction\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8da10e89-3f0f-4b96-8f7f-4cdfd3f16451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineage dataset\n",
    "class LineageDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        super().__init__()\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4593a208-4d4c-47b6-84e8-3636cb6a044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11f2a11c-9237-41c6-85ef-8071da745e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define node features\n",
    "node_feature_cols = ['area', 'centroid_y', \n",
    "       'axis_major_length', 'axis_minor_length', 'intensity_mean_phase',\n",
    "       'intensity_max_phase', 'intensity_min_phase', 'intensity_mean_fluor',\n",
    "       'intensity_max_fluor', 'intensity_min_fluor']\n",
    "\n",
    "for col in node_feature_cols:\n",
    "    df_cells.loc[:,col] = df_cells[col].astype(np.float32);   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "39b91a08-49df-4ebc-b399-3c9d096ad6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_sub_lineage_roots(df):\n",
    "    # Ensure relevant columns are present\n",
    "    required_cols = ['experiment_name', 'FOV', 'trench_id', 'ground_truth_lineage', 'time_frame', 'node_id']\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        raise ValueError(f\"DataFrame must contain all required columns: {required_cols}\")\n",
    "    df_temp_sorted = df.sort_values(by=['time_frame', 'node_id'])\n",
    "    first_appearances = df_temp_sorted.drop_duplicates(\n",
    "        subset=['experiment_name', 'FOV', 'trench_id', 'ground_truth_lineage'],\n",
    "        keep='first'\n",
    "    )\n",
    "\n",
    "    # Extract the necessary information for each root\n",
    "    # Convert to list of tuples as in the original function's output format\n",
    "    sub_lineage_roots = list(first_appearances[[\n",
    "        'experiment_name',\n",
    "        'FOV',\n",
    "        'trench_id',\n",
    "        'ground_truth_lineage',\n",
    "        'time_frame'\n",
    "    ]].itertuples(index=False, name=None))\n",
    "\n",
    "    return sub_lineage_roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f6b24623-d886-4673-95fd-80bf76954bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully created 34 PyG graphs, one per identified sub-lineage branch.\n"
     ]
    }
   ],
   "source": [
    "# create graphs\n",
    "sub_lineage_roots_tuples = identify_sub_lineage_roots(df_cells)\n",
    "branch_graphs_list = []\n",
    "\n",
    "for exp, fov, trench, root_lineage_str, start_t in sub_lineage_roots_tuples:\n",
    "    # Filter the DataFrame to include only the cells belonging to this specific sub-lineage branch\n",
    "    # and starting from its first appearance time\n",
    "    df_branch = df_cells[\n",
    "        (df_cells['experiment_name'] == exp) &\n",
    "        (df_cells['FOV'] == fov) &\n",
    "        (df_cells['trench_id'] == trench) &\n",
    "        (df_cells['time_frame'] >= start_t) &\n",
    "        # This regex ensures we only get descendants of this specific root_lineage_str\n",
    "        (df_cells['ground_truth_lineage'].apply(lambda x: x == root_lineage_str or x.startswith(f\"{root_lineage_str}.\")))\n",
    "    ].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "    # Ensure the branch actually has cells, otherwise skip\n",
    "    if not df_branch.empty:\n",
    "        #print(f\"Processing Sub-Lineage: '{root_lineage_str}' starting at t={start_t} (Exp: {exp}, FOV: {fov}, Trench: {trench})...\")\n",
    "        graph = create_lineage_graph(df_branch, device=device)\n",
    "        if graph is not None:\n",
    "            branch_graphs_list.append(graph)\n",
    "        else:\n",
    "            print(f\"  Skipped (no valid connections/nodes) for '{root_lineage_str}' at t={start_t}\")\n",
    "    else:\n",
    "        print(f\"  Skipped (empty DataFrame) for '{root_lineage_str}' at t={start_t}\")\n",
    "\n",
    "\n",
    "print(f\"\\nSuccessfully created {len(branch_graphs_list)} PyG graphs, one per identified sub-lineage branch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0fbee6a4-3f2a-4e40-936d-db6b09ea0132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Sub-Lineage Graph Details:\n",
      "\n",
      "--- Graph 1 ---\n",
      "Data(x=[359, 10], edge_index=[2, 342], edge_attr=[342, 11], y=[359], pos=[359, 1], num_nodes=359, time_frame=[359], root_lineage_branch='A.1.1.2', start_time_frame=0, experiment_name='DUMM_giTG69_Glucose_013025', fov='007', trench_id='295')\n",
      "  Nodes (x.shape): torch.Size([359, 10])\n",
      "  Edges (edge_index.shape): torch.Size([2, 342])\n",
      "  Labels (y.shape): torch.Size([359])\n",
      "  Root Lineage Branch ID: A.1.1.2\n",
      "  Start Time Frame: 0\n",
      "  Experiment Name: DUMM_giTG69_Glucose_013025\n",
      "  FOV: 007\n",
      "  Trench ID: 295\n",
      "\n",
      "--- Graph 2 ---\n",
      "Data(x=[267, 10], edge_index=[2, 259], edge_attr=[259, 11], y=[267], pos=[267, 1], num_nodes=267, time_frame=[267], root_lineage_branch='A.2.1.2.1', start_time_frame=1, experiment_name='DUMM_giTG69_Glucose_013025', fov='007', trench_id='295')\n",
      "  Nodes (x.shape): torch.Size([267, 10])\n",
      "  Edges (edge_index.shape): torch.Size([2, 259])\n",
      "  Labels (y.shape): torch.Size([267])\n",
      "  Root Lineage Branch ID: A.2.1.2.1\n",
      "  Start Time Frame: 1\n",
      "  Experiment Name: DUMM_giTG69_Glucose_013025\n",
      "  FOV: 007\n",
      "  Trench ID: 295\n",
      "\n",
      "--- Graph 3 ---\n",
      "Data(x=[91, 10], edge_index=[2, 86], edge_attr=[86, 11], y=[91], pos=[91, 1], num_nodes=91, time_frame=[91], root_lineage_branch='A.1.1.2', start_time_frame=2, experiment_name='DUMM_giTG69_Glucose_013025', fov='007', trench_id='295')\n",
      "  Nodes (x.shape): torch.Size([91, 10])\n",
      "  Edges (edge_index.shape): torch.Size([2, 86])\n",
      "  Labels (y.shape): torch.Size([91])\n",
      "  Root Lineage Branch ID: A.1.1.2\n",
      "  Start Time Frame: 2\n",
      "  Experiment Name: DUMM_giTG69_Glucose_013025\n",
      "  FOV: 007\n",
      "  Trench ID: 295\n"
     ]
    }
   ],
   "source": [
    "if branch_graphs_list:\n",
    "    print(\"\\nExample Sub-Lineage Graph Details:\")\n",
    "    for i, graph in enumerate(branch_graphs_list[:3]): # Print details for first 3 graphs\n",
    "        print(f\"\\n--- Graph {i+1} ---\")\n",
    "        print(graph)\n",
    "        print(f\"  Nodes (x.shape): {graph.x.shape}\")\n",
    "        print(f\"  Edges (edge_index.shape): {graph.edge_index.shape}\")\n",
    "        print(f\"  Labels (y.shape): {graph.y.shape}\")\n",
    "        print(f\"  Root Lineage Branch ID: {graph.root_lineage_branch}\")\n",
    "        print(f\"  Start Time Frame: {graph.start_time_frame}\")\n",
    "        print(f\"  Experiment Name: {graph.experiment_name}\")\n",
    "        print(f\"  FOV: {graph.fov}\")\n",
    "        print(f\"  Trench ID: {graph.trench_id}\")\n",
    "        # Optionally, print the actual ground truth lineage IDs in this subgraph for verification\n",
    "        # print(f\"  Included Lineages: {df_cells.loc[graph.node_id.cpu().numpy()]['ground_truth_lineage'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f6ca1d0e-0b10-4a28-ae49-fe4c5df55745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs: 34\n",
      "Number of training graphs: 23\n",
      "Number of validation graphs: 5\n",
      "Number of test graphs: 6\n"
     ]
    }
   ],
   "source": [
    "# Define split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15 \n",
    "\n",
    "# Ensure ratios sum to 1\n",
    "assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Ratios must sum to 1.\"\n",
    "\n",
    "# Sequentially split data because train_test_split can only split into 2 sets\n",
    "train_graphs, temp_graphs = train_test_split(\n",
    "    branch_graphs_list,\n",
    "    test_size=(val_ratio + test_ratio), # Combined size for validation and test\n",
    "    random_state=0 # set seed for reproducibility\n",
    ")\n",
    "\n",
    "# split temp_graphs into validation and test sets\n",
    "# (test_ratio / (val_ratio + test_ratio)) ensures the correct proportion from the temporary set\n",
    "val_graphs, test_graphs = train_test_split(\n",
    "    temp_graphs,\n",
    "    test_size=(test_ratio / (val_ratio + test_ratio)),\n",
    "    random_state=0 # set seed for reproducibility\n",
    ")\n",
    "\n",
    "print(f\"Total number of graphs: {len(branch_graphs_list)}\")\n",
    "print(f\"Number of training graphs: {len(train_graphs)}\")\n",
    "print(f\"Number of validation graphs: {len(val_graphs)}\")\n",
    "print(f\"Number of test graphs: {len(test_graphs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a4f48300-ca9f-4e62-80a9-6f5270428b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PyG Datasets created:\n",
      "Train dataset size: 23\n",
      "Validation dataset size: 5\n",
      "Test dataset size: 6\n"
     ]
    }
   ],
   "source": [
    "train_dataset = LineageDataset(train_graphs)\n",
    "val_dataset = LineageDataset(val_graphs)\n",
    "test_dataset = LineageDataset(test_graphs)\n",
    "\n",
    "print(\"\\nPyG Datasets created:\")\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7a07345e-8d65-4d78-818d-c0cb48e80338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of node features in dataset\n",
    "num_node_features = len(node_feature_cols)\n",
    "\n",
    "# Determine the dimensionality of the initial edge features\n",
    "# As per your DS_block, it's len(node_feature_cols) + 1 (for cosine similarity)\n",
    "initial_edge_feature_dim = len(node_feature_cols) + 1\n",
    "\n",
    "# Instantiate the model with the new parameters\n",
    "\n",
    "model = LineageLinkPredictionGNN(\n",
    "    in_channels=num_node_features,\n",
    "    initial_edge_channels=initial_edge_feature_dim, # <-- NEW REQUIRED ARGUMENT\n",
    "    hidden_channels=64, # tune (e.g., 16, 32, 128, 256)\n",
    "    num_blocks=2 # <-- NEW OPTIONAL ARGUMENT, paper suggests L blocks\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss() # For binary classification of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6aac22f1-b278-4b31-a9f7-303c249c511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Hyperparameters and Training Configuration ---\n",
    "epochs = 200 # You need to set the total number of training epochs\n",
    "learning_rate = 0.001\n",
    "hidden_channels = 128 # Example: for your GNN model\n",
    "initial_node_channels = 10 # Example: based on len(node_feature_cols)\n",
    "initial_edge_channels = 11 # Example: based on the output of your DS_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f24d212-eca4-425a-b496-2521fbed337c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting link prediction training with improved negative sampling...\n",
      "Epoch: 001, Train Loss: 0.6963, Val Loss: 2.1442, Val Acc: 0.1910\n",
      "Epoch: 002, Train Loss: 0.6947, Val Loss: 1.3850, Val Acc: 0.1910\n",
      "Epoch: 003, Train Loss: 0.6839, Val Loss: 2.0352, Val Acc: 0.1910\n",
      "Epoch: 004, Train Loss: 0.6796, Val Loss: 1.2075, Val Acc: 0.1910\n",
      "Epoch: 005, Train Loss: 0.6752, Val Loss: 0.7974, Val Acc: 0.3568\n",
      "Epoch: 006, Train Loss: 0.6704, Val Loss: 0.8771, Val Acc: 0.2563\n",
      "Epoch: 007, Train Loss: 0.6601, Val Loss: 1.0731, Val Acc: 0.2060\n",
      "Epoch: 008, Train Loss: 0.6573, Val Loss: 1.0615, Val Acc: 0.2060\n",
      "Epoch: 009, Train Loss: 0.6510, Val Loss: 1.0568, Val Acc: 0.2563\n",
      "Epoch: 010, Train Loss: 0.6467, Val Loss: 1.0725, Val Acc: 0.2312\n",
      "Epoch: 011, Train Loss: 0.6447, Val Loss: 1.7366, Val Acc: 0.1910\n",
      "Epoch: 012, Train Loss: 0.6433, Val Loss: 1.2357, Val Acc: 0.1910\n",
      "Epoch: 013, Train Loss: 0.6303, Val Loss: 1.1381, Val Acc: 0.2010\n",
      "Epoch: 014, Train Loss: 0.6346, Val Loss: 1.0771, Val Acc: 0.2010\n",
      "Epoch: 015, Train Loss: 0.6207, Val Loss: 0.9637, Val Acc: 0.2111\n",
      "Epoch: 016, Train Loss: 0.6177, Val Loss: 0.9204, Val Acc: 0.2261\n",
      "Epoch: 017, Train Loss: 0.6084, Val Loss: 0.8910, Val Acc: 0.2613\n",
      "Epoch: 018, Train Loss: 0.6022, Val Loss: 0.8753, Val Acc: 0.2663\n",
      "Epoch: 019, Train Loss: 0.5931, Val Loss: 0.8881, Val Acc: 0.2714\n",
      "Epoch: 020, Train Loss: 0.5898, Val Loss: 0.8544, Val Acc: 0.2864\n",
      "Epoch: 021, Train Loss: 0.5860, Val Loss: 0.8294, Val Acc: 0.2563\n",
      "Epoch: 022, Train Loss: 0.5805, Val Loss: 0.8564, Val Acc: 0.2211\n",
      "Epoch: 023, Train Loss: 0.5792, Val Loss: 0.8704, Val Acc: 0.2161\n",
      "Epoch: 024, Train Loss: 0.5768, Val Loss: 0.8124, Val Acc: 0.2915\n",
      "Epoch: 025, Train Loss: 0.5672, Val Loss: 0.7553, Val Acc: 0.4824\n",
      "Epoch: 026, Train Loss: 0.5689, Val Loss: 0.7422, Val Acc: 0.4824\n",
      "Epoch: 027, Train Loss: 0.5730, Val Loss: 0.7957, Val Acc: 0.3769\n",
      "Epoch: 028, Train Loss: 0.5572, Val Loss: 0.8705, Val Acc: 0.2613\n",
      "Epoch: 029, Train Loss: 0.5546, Val Loss: 0.8583, Val Acc: 0.2563\n",
      "Epoch: 030, Train Loss: 0.5572, Val Loss: 0.7924, Val Acc: 0.3467\n",
      "Epoch: 031, Train Loss: 0.5557, Val Loss: 0.7570, Val Acc: 0.5075\n",
      "Epoch: 032, Train Loss: 0.5486, Val Loss: 0.7651, Val Acc: 0.5879\n",
      "Epoch: 033, Train Loss: 0.5485, Val Loss: 0.7747, Val Acc: 0.5930\n",
      "Epoch: 034, Train Loss: 0.5428, Val Loss: 0.8037, Val Acc: 0.4472\n",
      "Epoch: 035, Train Loss: 0.5459, Val Loss: 0.8309, Val Acc: 0.3518\n",
      "Epoch: 036, Train Loss: 0.5505, Val Loss: 0.8333, Val Acc: 0.3568\n",
      "Epoch: 037, Train Loss: 0.5447, Val Loss: 0.8190, Val Acc: 0.4523\n",
      "Epoch: 038, Train Loss: 0.5461, Val Loss: 0.8276, Val Acc: 0.5075\n",
      "Epoch: 039, Train Loss: 0.5357, Val Loss: 0.8491, Val Acc: 0.5578\n",
      "Epoch: 040, Train Loss: 0.5503, Val Loss: 0.8631, Val Acc: 0.5678\n",
      "Epoch: 041, Train Loss: 0.5449, Val Loss: 0.9135, Val Acc: 0.4724\n",
      "Epoch: 042, Train Loss: 0.5379, Val Loss: 0.9513, Val Acc: 0.4422\n",
      "Epoch: 043, Train Loss: 0.5392, Val Loss: 1.1626, Val Acc: 0.4020\n",
      "Epoch: 044, Train Loss: 0.5437, Val Loss: 1.2658, Val Acc: 0.4372\n",
      "Epoch: 045, Train Loss: 0.5479, Val Loss: 1.1031, Val Acc: 0.4925\n",
      "Epoch: 046, Train Loss: 0.5369, Val Loss: 1.0316, Val Acc: 0.5075\n",
      "Epoch: 047, Train Loss: 0.5506, Val Loss: 0.9060, Val Acc: 0.5930\n",
      "Epoch: 048, Train Loss: 0.5424, Val Loss: 0.8175, Val Acc: 0.6784\n",
      "Epoch: 049, Train Loss: 0.5389, Val Loss: 0.7741, Val Acc: 0.7186\n",
      "Epoch: 050, Train Loss: 0.5394, Val Loss: 0.7594, Val Acc: 0.7487\n",
      "Epoch: 051, Train Loss: 0.5464, Val Loss: 0.7426, Val Acc: 0.7588\n",
      "Epoch: 052, Train Loss: 0.5398, Val Loss: 0.7230, Val Acc: 0.7839\n",
      "Epoch: 053, Train Loss: 0.5430, Val Loss: 0.7174, Val Acc: 0.7889\n",
      "Epoch: 054, Train Loss: 0.5395, Val Loss: 0.7438, Val Acc: 0.7387\n"
     ]
    }
   ],
   "source": [
    "# Define your radius_threshold based on your data's spatial scale\n",
    "my_radius_threshold = 50.0 # Example value, adjust this for your data!\n",
    "\n",
    "print(\"\\nStarting link prediction training with improved negative sampling...\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train_link_prediction(model, train_loader, optimizer, criterion, device, neg_sample_ratio=1.0, radius_threshold=my_radius_threshold)\n",
    "    val_loss, val_acc = evaluate_link_prediction(model, val_loader, criterion, device, neg_sample_ratio=1.0, radius_threshold=my_radius_threshold)\n",
    "\n",
    "    print(f'Epoch: {epoch:03d}, '\n",
    "          f'Train Loss: {train_loss:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "# --- Final Evaluation on Test Set ---\n",
    "print(\"\\nEvaluating on test set with improved negative sampling...\")\n",
    "test_loss, test_acc = evaluate_link_prediction(model, test_loader, criterion, device, neg_sample_ratio=1.0, radius_threshold=my_radius_threshold)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf81211f-9480-4e2b-8d2a-c1690e74d584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
