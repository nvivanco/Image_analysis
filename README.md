# DuMM Bacteria Tracker (GNN-Based Cell Lineage Tracking)

This repository contains the source code for the **DuMM Bacteria Tracker**, a Python package (`mmtrack`) dedicated to highly accurate cell segmentation and lineage tracking for single-cell time-lapse microscopy data, particularly within **Mother Machine** devices.

The cell tracking component utilizes a custom **Graph Neural Network (GNN)** architecture for robust link prediction across time steps. The trained model weights are hosted separately on the [Hugging Face Hub](https://www.google.com/search?q=https://huggingface.co/nvivanco/DuMM_bacteria_track).

-----

## 1\. Installation and Setup

We use **Poetry** for dependency management to ensure a reproducible environment.

### Prerequisites

  * Python **3.11.8**
  * **Poetry** (install via `pip install poetry`)

### Setup Steps

1.  **Clone the Repository:**

    ```bash
    git clone <YOUR_REPO_URL>
    cd <repo-name>
    ```

2.  **Install Dependencies:** Poetry will create a new virtual environment using the specified Python version and install all packages defined in `pyproject.toml`.

    ```bash
    poetry install
    ```

3.  **Download Trained GNN Model Weights:** The trained GNN weights are hosted on the Hugging Face Hub to keep this repository small. Run the included script to download the model into the local `models/` directory.

    ```bash
    poetry run python download_assets.py
    ```

    *Note: This command saves the `best_link_prediction_model.pt` file to your local machine for inference.*

-----

## 2\. Usage and Tutorial (todo: update)

## Running Stage 1: Image Correction

The script `01_image_correction.py` executes the initial pre-processing steps: drift correction, rotation, and channel extraction. It saves the resulting image files for use in the next pipeline stage.

### Basic Execution

Run the script from your project root, replacing the placeholder paths with the actual locations of your raw TIFF data and where you want the processed images to be saved.

```bash
# Example: Use default parameters
poetry run python 01_image_correction.py \
    --input-dir '<path/to/raw/data/DIMM_CL008_072225>' \
    --output-dir './processed_images'
```

### User Action and Output

Upon successful completion, the script will output the path to the extracted image files. **You must inspect these files** to determine the necessary IDs for background subtraction in Stage 2.

```markdown
#################################################################
## USER ACTION REQUIRED: Inspect TRENCH MASKS and TIME-LAPSE   ##
## Next Step: Determine 'empty_stack_id' and 'ana_peak_ids'. ##
## Use <path_to_mm_channels> as the input for Stage 2.         ##
#################################################################
```

### Overriding Default Parameters

The script provides several optional arguments to handle different experimental setups. You can view all options using the `--help` flag:

```bash
poetry run python 01_image_correction.py --help
```

| Parameter | Type | Default | Description |
| :--- | :--- | :--- | :--- |
| `--input-dir` | `str` | *N/A* | **(Required)** Path to the directory containing the raw TIFF stacks. |
| `--output-dir` | `str` | *N/A* | **(Required)** Base path for saving corrected and processed images. |
| `--phase-channel-idx` | `int` | `0` | Index of the phase contrast channel (`c` parameter). |
| `--fast-drift-correction` | `bool` | `True` | Use the fast drift correction method (`fast4`). |
| `--growth-channel-length` | `int` | `400` | Approx. pixel length for the Mother Machine channel. |
| `--trench-ends-orientation` | `str` | `'down'` | Orientation of the closed trench ends (`closed_ends` parameter). Choices: `up`, `down`, `none`. |

**Example of overriding defaults:**

If your phase channel is index 1 and you are not using the fast drift correction:

```bash
poetry run python 01_image_correction.py \
    --input-dir '<path/to/raw/data>' \
    --output-dir './processed_images' \
    --phase-channel-idx 1 \
    --fast-drift-correction False
```


## Running Stage 2: Background Subtraction ðŸ”¬

The script `02_background_subtraction.py` performs phase contrast and fluorescence background subtraction using an empty trench identified by the user in the previous stage.

This script requires several **mandatory** parameters determined by visual inspection of the images output from Stage 1.

### Basic Execution

Run the script from your project root.

You must provide the following **mandatory** arguments:

1.  **`--input-path`**: The output directory generated by `01_image_correction.py` (e.g., `./processed_images/.../mm_channels`).
2.  **`--fov`**: The Field of View ID you are analyzing (e.g., `'007'`).
3.  **`--empty-stack-id`**: The ID of the empty trench chosen for background subtraction (e.g., `'765'`).
4.  **`--ana-peak-ids`**: A space-separated list of the trench IDs that contain cells to be analyzed (e.g., `'992' '1219' '1749'`).

<!-- end list -->

```bash
# Example: Replace values based on your inspection
poetry run python 02_background_subtraction.py \
    --input-path './processed_images/DIMM_CL008_072225/mm_channels' \
    --fov '007' \
    --empty-stack-id '765' \
    --ana-peak-ids '992' '1219' '1749'
```

### Overriding Default Parameters

The script provides optional arguments to specify the channel indices if they differ from the standard configuration.

| Parameter | Type | Default | Description |
| :--- | :--- | :--- | :--- |
| `--input-path` | `str` | *N/A* | **(Required)** Path to the extracted channel data (output of Stage 1). |
| `--fov` | `str` | *N/A* | **(Required)** Field of View ID (e.g., '007'). |
| `--empty-stack-id` | `str` | *N/A* | **(Required)** ID of the empty stack for background. |
| `--ana-peak-ids` | `str` (list) | *N/A* | **(Required)** Space-separated list of trench IDs to analyze. |
| `--phase-index` | `int` | `0` | The channel index for **Phase Contrast** subtraction. |
| `--fluor-index` | `int` | `1` | The channel index for **Fluorescence** subtraction. |

**Example of overriding channel indices:**

If Phase is at index 2 and Fluorescence is at index 3:

```bash
poetry run python 02_background_subtraction.py \
    --input-path './processed_images/mm_channels' \
    --fov '007' \
    --empty-stack-id '765' \
    --ana-peak-ids '992' '1219' '1749' \
    --phase-index 2 \
    --fluor-index 3
```


## 3\. GNN Model and Training Details

The core tracking logic relies on a custom Graph Neural Network architecture. Full details on the architecture and performance metrics are available on the [Hugging Face Model Card](https://www.google.com/search?q=https://huggingface.co/nvivanco/DuMM_bacteria_track).

### Architecture (`LineageLinkPredictionGNN`)

  * **Type:** Edge-Propagation Message Passing Neural Network (EP-MPNN) used for Link Prediction.
  * **Layers:** 2 custom `EP_MPNN_Block` layers followed by a **Jumping Knowledge (JK)** aggregation layer.
  * **Prediction:** The decoder predicts the probability of a link by combining the aggregated node embeddings and the current edge attributes.

### Training Methodology

| Component | Detail |
| :--- | :--- |
| **Node Features** | **10 scalar features** (area, centroid position, axis lengths, mean/max/min intensity from Phase Contrast and Fluorescence channels). |
| **Data Split** | **Time-based temporal split:** 60% Train, 20% Validation, 20% Test (based on chronological time frames). |
| **Normalization** | **Standard Scaling (`StandardScaler`)** fitted exclusively on the training set. |
| **Key Hyperparameters** | **Hidden Channels:** 128; **Optimizer:** Adam (LR: 0.001, Weight Decay: 0.0005). |
| **Stopping Criteria** | Early stopping based on **Validation Loss** with a patience of 10 epochs. |

-----

## 4\. Licensing and Citation

### License

This project is released under the **MIT License**. For the full license text, see the `LICENSE` file.

### Citation

If you use this code or the trained model in your research, please cite the following original works that inspired the methodology:

  * **Cell Segmentation (adapted from napari-mm3):**

    > R. Thiermann et al., "Tools and methods for high-throughput single-cell imaging with the mother machine," *eLife*, vol. 12, p. RP88463, 2023.

  * **Cell Tracking GNN (inspired by Cell-tracker-GNN):**

    > T. Ben-Haim and T. Riklin-Raviv, "Graph Neural Network for Cell Tracking in Microscopy Videos," in *Proceedings of the European Conference on Computer Vision (ECCV)*, 2022.
