{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import tifffile\n",
    "import cv2\n",
    "import math\n",
    "from napari_correct_drift import CorrectDrift\n",
    "from skimage import filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6edfb9-233e-400f-9137-aed649d59bcb",
   "metadata": {},
   "source": [
    "# MM3 req 1: Channels are mostly vertical\n",
    "# MM3 Req 2: Channels have at least 20 pixels from their ends to the top and bottom edge of the image\n",
    "Channel ends are in the top and bottom third of the image, regardless of orientation.\n",
    "There are no artefacts in the image above and below the channels. The numbers on the mother machine can confuse the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbe37c5-3ebe-46e4-bca4-1b1a2c7adcf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root_dir = '/Users/nvivanco/Desktop/20240926/dimm_giTG69_glucose_1'\n",
    "unstacked_path = napari_ready_format_drift_correct(root_dir, 'dimm', c = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46eda9e-a50c-460a-94dd-2d3d964f53de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unstacked_path = '/Users/nvivanco/Desktop/20240926/dimm_giTG69_glucose_1/hyperstacked/drift_corrected/cyx_files_for_mm3'\n",
    "plot_lines_across_FOVs(unstacked_path, c = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c3200c-f8f7-40d0-9d20-743e03892d97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rotate_stack(unstacked_path, c = 0, growth_channel_length = 290)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae6da0-0c17-4309-84f5-0859924ef0b6",
   "metadata": {},
   "source": [
    "# Why are trenches not getting detected? This is the function in napari mm3 compile.py responsible for identifying trenches/peaks/microfluidic channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b93651-ff2a-4937-962f-4260c34b36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstacked_path = '/Users/nvivanco/Desktop/20240926/dimm_giTG69_glucose_1/hyperstacked/drift_corrected/cyx_files_for_mm3/rotated/xy006'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f7038-2c57-4b2f-9ef6-21f2be3db7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = org_by_timepoint([unstacked_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc91dd-9684-4cfa-912d-5070a870191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f3fda-fdff-480c-9a02-8107e05fef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_path = file_dict['006'][0]['stacked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b1f0f2-a9f2-432b-9068-7297e2fcf005",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6fb920-cb27-4a96-b9c9-a066049fb810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I counted 31 peaks in this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc276bec-57e4-4975-a3f9-19e3c64713bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks_cwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3d7ed-e9ea-4e93-b9d4-bb26b4d5115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = tifffile.TiffFile(ex_path).asarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cab8a3-305c-4f85-ac39-ff88de130844",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4683d10-3df4-41a9-914d-baf527e9ab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_x = image_data[0].sum(axis=0).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa4b33c-3c3d-44b3-9516-983db6c0d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_x.shape #only trying phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264a73d-15d6-41c9-8612-549916acf1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_w = 10\n",
    "chan_sep = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9443f4-706e-4e3c-998b-aee7d40aa936",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(chan_w - 5, chan_w + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8ab79-16b9-4fb6-a0cd-14f9f77812c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_snr determines the number of peaks, I'm not sure where chan_snr = params[\"compile\"][\"channel_detection_snr\"] comes from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b009944-3b79-43be-a87e-e8a1ea5ce491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find_peaks_cwt is a function which attempts to find the peaks in a 1-D array by\n",
    "# convolving it with a wave. here the wave is the default Mexican hat wave\n",
    "# but the minimum signal to noise ratio is specified\n",
    "# *** The range here should be a parameter or changed to a fraction.\n",
    "peaks = find_peaks_cwt(\n",
    "    projection_x, np.arange(chan_w - 5, chan_w + 5), min_snr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15a25e-881a-4dca-b984-866e4473acbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a572b0a-9589-42da-a17e-f7f1b1263bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the left-most peak position is within half of a channel separation,\n",
    "# discard the channel from the list.\n",
    "if peaks[0] < (chan_sep / 2):\n",
    "    peaks = peaks[1:]\n",
    "# If the diference between the right-most peak position and the right edge\n",
    "# of the image is less than half of a channel separation, discard the channel.\n",
    "if image_data.shape[1] - peaks[-1] < (chan_sep / 2):\n",
    "    peaks = peaks[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0144776-826e-4154-9780-0b120da66d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa142f9-53c9-4290-912b-e9dabceac5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average channel ends for the y-projected image\n",
    "projection_y = image_data[0].sum(axis=1)\n",
    "# find derivative, must use int32 because it was unsigned 16b before.\n",
    "proj_y_d = np.diff(projection_y.astype(np.int32))\n",
    "# use the top third to look for closed end, is pixel location of highest deriv\n",
    "onethirdpoint_y = int(projection_y.shape[0] / 3.0)\n",
    "default_closed_end_px = proj_y_d[:onethirdpoint_y].argmax()\n",
    "# use bottom third to look for open end, pixel location of lowest deriv\n",
    "twothirdpoint_y = int(projection_y.shape[0] * 2.0 / 3.0)\n",
    "default_open_end_px = twothirdpoint_y + proj_y_d[twothirdpoint_y:].argmin()\n",
    "default_length = default_open_end_px - default_closed_end_px  # used for checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e41fc9-1cff-4eba-be28-a43d08cd61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_wp = 10\n",
    "# go through peaks and assign information\n",
    "# dict for channel dimensions\n",
    "chnl_loc_dict = {}\n",
    "# key is peak location, value is dict with {'closed_end_px': px, 'open_end_px': px}\n",
    "\n",
    "for peak in peaks:\n",
    "    # set defaults\n",
    "    chnl_loc_dict[peak] = {\n",
    "        \"closed_end_px\": default_closed_end_px,\n",
    "        \"open_end_px\": default_open_end_px,\n",
    "    }\n",
    "    # redo the previous y projection finding with just this channel\n",
    "    channel_slice = image_data[0][:, peak - crop_wp : peak + crop_wp]\n",
    "    slice_projection_y = channel_slice.sum(axis=1)\n",
    "    slice_proj_y_d = np.diff(slice_projection_y.astype(np.int32))\n",
    "    slice_closed_end_px = slice_proj_y_d[:onethirdpoint_y].argmax()\n",
    "    slice_open_end_px = twothirdpoint_y + slice_proj_y_d[twothirdpoint_y:].argmin()\n",
    "    slice_length = slice_open_end_px - slice_closed_end_px\n",
    "\n",
    "    # check if these values make sense. If so, use them. If not, use default\n",
    "    # make sure lenght is not 30 pixels bigger or smaller than default\n",
    "    # *** This 15 should probably be a parameter or at least changed to a fraction.\n",
    "    if slice_length + 15 < default_length or slice_length - 15 > default_length:\n",
    "        continue\n",
    "    # make sure ends are greater than 15 pixels from image edge\n",
    "    if slice_closed_end_px < 15 or slice_open_end_px > image_data.shape[0] - 15:\n",
    "        continue\n",
    "\n",
    "    # if you made it to this point then update the entry\n",
    "    chnl_loc_dict[peak] = {\n",
    "        \"closed_end_px\": slice_closed_end_px,\n",
    "        \"open_end_px\": slice_open_end_px,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a7540-4767-40e5-8e53-0e4c57c838b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rows= image_data.shape[1]\n",
    "image_cols= image_data.shape[2]\n",
    "crop_wp= 10\n",
    "chan_lp= 10\n",
    "crop_wp = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf9267-11a3-4da1-b581-915ab45f51e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_corners_dict = {}\n",
    "consensus_mask = np.zeros([image_rows, image_cols])  # mask for labeling entire image\n",
    "# for each trench in each image make a single mask\n",
    "img_chnl_mask = np.zeros([image_rows, image_cols])\n",
    "\n",
    "# and add the channel/peak mask to it\n",
    "# Assuming chnl_loc_dict is a NumPy array\n",
    "for chnl_peak in chnl_loc_dict:\n",
    "    peak_ends = chnl_loc_dict[chnl_peak]\n",
    "    # pull out the peak location and top and bottom location\n",
    "    # and expand by padding \n",
    "    x1 = max(chnl_peak- crop_wp, 0)\n",
    "    x2 = min(chnl_peak + crop_wp, image_cols)\n",
    "    y1 = max(peak_ends[\"closed_end_px\"] - chan_lp, 0)\n",
    "    y2 = min(peak_ends[\"open_end_px\"] + chan_lp, image_rows)\n",
    "    mask_corners_dict[chnl_peak] = [y1, y2, x1, x2]\n",
    "\n",
    "    # add it to the mask for this image\n",
    "    img_chnl_mask[y1:y2, x1:x2] = 1\n",
    "\n",
    "# add it to the consensus mask\n",
    "consensus_mask += img_chnl_mask\n",
    "\n",
    "# Normalize consensus mask between 0 and 1.\n",
    "consensus_mask = consensus_mask.astype(\"float32\") / float(np.amax(consensus_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0591bc06-74d7-46a6-a9e7-5d97c6cfcbea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_data[0], cmap='gray')\n",
    "plt.title('Channel mask')\n",
    "plt.axis('off')  # Hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549bab67-c912-49c6-8047-b17384375417",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(consensus_mask, cmap='gray')\n",
    "plt.title('Channel mask')\n",
    "plt.axis('off')  # Hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabdcd77-5e38-406a-b019-159f0248e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image = image_data[0]*consensus_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14e337-7d40-4bbd-943a-65d6ea71e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e6d33-db81-4efc-86b5-8569d7fcfd31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(masked_image, cmap='gray')\n",
    "plt.title('Channel mask')\n",
    "plt.axis('off')  # Hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9440a-d2d2-4ff6-8eb3-3adb8acdbe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_corners_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4f5af-e19b-4a8e-8bcf-ad036b88d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1,y2, x1,x2= mask_corners_dict[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50489e6-7785-4a4d-a9e0-9a68c44a46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_data[0][y1:y2, x1:x2], cmap='gray')\n",
    "plt.title('Channel mask')\n",
    "plt.axis('off')  # Hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a38664-d7d6-4479-a1ff-a17d281ddfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract trenches and save as stacked TIFF images\n",
    "for trench in mask_corners_dict.keys():\n",
    "    y1,y2, x1,x2= mask_corners_dict[trench]\n",
    "    trench_region = image_data[:, y1:y2, x1:x2]# assuming image is stacked as c y x\n",
    "    filename = f'region_{trench}.tif'\n",
    "    path = os.path.join(unstacked_path, filename)\n",
    "    tifffile.imwrite(path, trench_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1dee88-e2b8-4ccd-95a9-ccd3913cc5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_consensus_mask(\n",
    "    fov: int,\n",
    "    analyzed_imgs: dict,\n",
    "    image_rows: int,\n",
    "    image_cols: int,\n",
    "    crop_wp: int,\n",
    "    chan_lp: int,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate consensus channel mask for a given fov.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fov: int\n",
    "        fov to analyze\n",
    "    analyzed_imgs: dict\n",
    "        image data\n",
    "    image_rows: int\n",
    "        image height\n",
    "    image_cols: int\n",
    "        image width\n",
    "    crop_wp: int\n",
    "        channel width padding\n",
    "    crop_lp: int\n",
    "        channel_width padding\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    consensus_mask: np.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    consensus_mask = np.zeros([image_rows, image_cols])  # mask for labeling\n",
    "\n",
    "    # bring up information for each image\n",
    "    for img_k in analyzed_imgs.keys():\n",
    "        img_v = analyzed_imgs[img_k]\n",
    "        # skip this one if it is not of the current fov\n",
    "        if img_v[\"fov\"] != fov:\n",
    "            continue\n",
    "\n",
    "        # for each channel in each image make a single mask\n",
    "        img_chnl_mask = np.zeros([image_rows, image_cols])\n",
    "\n",
    "        # and add the channel mask to it\n",
    "        for chnl_peak, peak_ends in six.iteritems(img_v[\"channels\"]):\n",
    "            # pull out the peak location and top and bottom location\n",
    "            # and expand by padding (more padding done later for width)\n",
    "            x1 = max(chnl_peak - crop_wp, 0)\n",
    "            x2 = min(chnl_peak + crop_wp, image_cols)\n",
    "            y1 = max(peak_ends[\"closed_end_px\"] - chan_lp, 0)\n",
    "            y2 = min(peak_ends[\"open_end_px\"] + chan_lp, image_rows)\n",
    "\n",
    "            # add it to the mask for this image\n",
    "            img_chnl_mask[y1:y2, x1:x2] = 1\n",
    "\n",
    "        # add it to the consensus mask\n",
    "        consensus_mask += img_chnl_mask\n",
    "\n",
    "    # Normalize consensus mask between 0 and 1.\n",
    "    consensus_mask = consensus_mask.astype(\"float32\") / float(np.amax(consensus_mask))\n",
    "\n",
    "    # threshhold and homogenize each channel mask within the mask, label them\n",
    "    # label when value is above 0.1 (so 90% occupancy), transpose.\n",
    "    # the [0] is for the array ([1] is the number of regions)\n",
    "    # It transposes and then transposes again so regions are labeled left to right\n",
    "    # clear border it to make sure the channels are off the edge\n",
    "    consensus_mask = ndi.label(consensus_mask)[0]\n",
    "\n",
    "    return consensus_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83eb00-dc6b-4057-aad7-c736aa3b8d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_channel_locs(params: dict, image_data: np.ndarray) -> dict:\n",
    "    \"\"\"Finds the location of channels from a phase contrast image. The channels are returned in\n",
    "    a dictionary where the key is the x position of the channel in pixel and the value is a\n",
    "    dicionary with the open and closed end in pixels in y.\n",
    "\n",
    "\n",
    "    Called by\n",
    "    get_tif_params\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # declare temp variables from yaml parameter dict.\n",
    "    chan_w = params[\"compile\"][\"channel_width\"]\n",
    "    chan_sep = params[\"compile\"][\"channel_separation\"]\n",
    "    crop_wp = int(params[\"compile\"][\"channel_width_pad\"] + chan_w / 2)\n",
    "    chan_snr = params[\"compile\"][\"channel_detection_snr\"]\n",
    "\n",
    "    # Detect peaks in the x projection (i.e. find the channels)\n",
    "    projection_x = image_data.sum(axis=0).astype(np.int32)\n",
    "    # find_peaks_cwt is a function which attempts to find the peaks in a 1-D array by\n",
    "    # convolving it with a wave. here the wave is the default Mexican hat wave\n",
    "    # but the minimum signal to noise ratio is specified\n",
    "    # *** The range here should be a parameter or changed to a fraction.\n",
    "    peaks = find_peaks_cwt(\n",
    "        projection_x, np.arange(chan_w - 5, chan_w + 5), min_snr=chan_snr\n",
    "    )\n",
    "\n",
    "    # If the left-most peak position is within half of a channel separation,\n",
    "    # discard the channel from the list.\n",
    "    if peaks[0] < (chan_sep / 2):\n",
    "        peaks = peaks[1:]\n",
    "    # If the diference between the right-most peak position and the right edge\n",
    "    # of the image is less than half of a channel separation, discard the channel.\n",
    "    if image_data.shape[1] - peaks[-1] < (chan_sep / 2):\n",
    "        peaks = peaks[:-1]\n",
    "\n",
    "    # Find the average channel ends for the y-projected image\n",
    "    projection_y = image_data.sum(axis=1)\n",
    "    # find derivative, must use int32 because it was unsigned 16b before.\n",
    "    proj_y_d = np.diff(projection_y.astype(np.int32))\n",
    "    # use the top third to look for closed end, is pixel location of highest deriv\n",
    "    onethirdpoint_y = int(projection_y.shape[0] / 3.0)\n",
    "    default_closed_end_px = proj_y_d[:onethirdpoint_y].argmax()\n",
    "    # use bottom third to look for open end, pixel location of lowest deriv\n",
    "    twothirdpoint_y = int(projection_y.shape[0] * 2.0 / 3.0)\n",
    "    default_open_end_px = twothirdpoint_y + proj_y_d[twothirdpoint_y:].argmin()\n",
    "    default_length = default_open_end_px - default_closed_end_px  # used for checks\n",
    "\n",
    "    # go through peaks and assign information\n",
    "    # dict for channel dimensions\n",
    "    chnl_loc_dict = {}\n",
    "    # key is peak location, value is dict with {'closed_end_px': px, 'open_end_px': px}\n",
    "\n",
    "    for peak in peaks:\n",
    "        # set defaults\n",
    "        chnl_loc_dict[peak] = {\n",
    "            \"closed_end_px\": default_closed_end_px,\n",
    "            \"open_end_px\": default_open_end_px,\n",
    "        }\n",
    "        # redo the previous y projection finding with just this channel\n",
    "        channel_slice = image_data[:, peak - crop_wp : peak + crop_wp]\n",
    "        slice_projection_y = channel_slice.sum(axis=1)\n",
    "        slice_proj_y_d = np.diff(slice_projection_y.astype(np.int32))\n",
    "        slice_closed_end_px = slice_proj_y_d[:onethirdpoint_y].argmax()\n",
    "        slice_open_end_px = twothirdpoint_y + slice_proj_y_d[twothirdpoint_y:].argmin()\n",
    "        slice_length = slice_open_end_px - slice_closed_end_px\n",
    "\n",
    "        # check if these values make sense. If so, use them. If not, use default\n",
    "        # make sure lenght is not 30 pixels bigger or smaller than default\n",
    "        # *** This 15 should probably be a parameter or at least changed to a fraction.\n",
    "        if slice_length + 15 < default_length or slice_length - 15 > default_length:\n",
    "            continue\n",
    "        # make sure ends are greater than 15 pixels from image edge\n",
    "        if slice_closed_end_px < 15 or slice_open_end_px > image_data.shape[0] - 15:\n",
    "            continue\n",
    "\n",
    "        # if you made it to this point then update the entry\n",
    "        chnl_loc_dict[peak] = {\n",
    "            \"closed_end_px\": slice_closed_end_px,\n",
    "            \"open_end_px\": slice_open_end_px,\n",
    "        }\n",
    "\n",
    "    return chnl_loc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc766d-7800-40f5-bb7e-634bc8fc1e99",
   "metadata": {},
   "source": [
    "# Functions for pre-processing mother machine images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860f72f-24a1-49a6-b5fe-a4494a4abc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint_distance(line, center):\n",
    "    # Function to calculate line midpoint distance\n",
    "    midpoint_x = (line[0][0] + line[0][2]) / 2\n",
    "    midpoint_y = (line[0][1] + line[0][3]) / 2\n",
    "    distance = np.sqrt((midpoint_x - center[0])**2 + (midpoint_y - center[1])**2)\n",
    "    return distance\n",
    "\n",
    "def crop_around_central_flow(h_lines, w, h, growth_channel_length= 150):\n",
    "    threshold = 200 # distance from center of image\n",
    "    center_x, center_y = w // 2, h // 2\n",
    "    if h_lines is not None:\n",
    "        # Filter lines based on distance\n",
    "        filtered_lines = []\n",
    "        for line in h_lines:\n",
    "            distance = midpoint_distance(line, (center_x, center_y))\n",
    "            if distance <= threshold:\n",
    "                filtered_lines.append(line)\n",
    "        x1, y1, x2, y2 = filtered_lines[0][0]\n",
    "\n",
    "        # Determine crop boundaries\n",
    "        crop_start = max(y1 - growth_channel_length, 0)\n",
    "        crop_end = min(y1 + 150, h)\n",
    "\n",
    "        print('Cropping reference image')\n",
    "\n",
    "        return crop_start, crop_end\n",
    "\n",
    "    else:\n",
    "        print('Warning: horizontal lines were not detected')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2ce05-e558-49c3-963c-b9d5be588b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_stack(path_to_stack, c = 0, growth_channel_length = 295):\n",
    "    \"\"\"Args:\n",
    "    path_to_stack: Path to stack of cyx format files, in string format\n",
    "    c: Phase channel index in integer format, default = 0\n",
    "    orientation: Orientation of lines to use to rotate and crop files, \n",
    "    value is a string indicating \"horizontal\" or \"vertical\". Defualt is vertical.\n",
    "    growth_channel_length: length in pixels of growth channel. \n",
    "    Shorter channels are approx 130 pixels. 150 is default.\n",
    "    \"\"\"\n",
    "    ## I want to make this work in tcyx files, because I can skip unstacking the drift corrected files if I isolate trenches with my own code and don't use napari-mm3\n",
    "    #create an output directory for the rotated files\n",
    "    path_to_rotated_images = os.path.join(path_to_stack, 'rotated')\n",
    "    os.makedirs(path_to_rotated_images, exist_ok=True)\n",
    "\n",
    "    file_groups = org_by_timepoint([path_to_stack])\n",
    "\n",
    "    for position in file_groups.keys():\n",
    "        earliest_timepoint = min(file_groups[position].keys())\n",
    "        first_file_path = file_groups[position][earliest_timepoint]['stacked']\n",
    "        print(first_file_path)\n",
    "        ref_img = tifffile.imread(first_file_path)\n",
    "        ref_phase_img = ref_img[c, :, :]\n",
    "        h, w = ref_phase_img.shape\n",
    "        horizontal_lines, vertical_lines = id_lines(ref_phase_img)\n",
    "        rotation_angle = calculate_rotation_angle(ref_phase_img, horizontal_lines)\n",
    "        ref_rotated_image = apply_image_rotation(ref_phase_img, rotation_angle)\n",
    "        rot_horizontal_lines, rot_vertical_lines = id_lines(ref_rotated_image)\n",
    "        crop_start, crop_end = crop_around_central_flow(rot_horizontal_lines, w, h, growth_channel_length)\n",
    "        ref_cropped_img = ref_rotated_image[crop_start:crop_end, :]\n",
    "        print('Lines identified in FOV ' + position)\n",
    "        plt.figure()\n",
    "        plt.imshow(ref_cropped_img, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        #apply rotation and crop to all other images in path\n",
    "        for time in file_groups[position]:\n",
    "            path = file_groups[position][time]['stacked']\n",
    "            time_img = tifffile.imread(path)\n",
    "            rotated_image = apply_image_rotation(time_img, rotation_angle)\n",
    "            cropped_img = rotated_image[:, crop_start:crop_end, :]\n",
    "            filename = os.path.basename(path)\n",
    "            new_filename = f'rotated_{filename}'\n",
    "            new_path = os.path.join(path_to_rotated_images, new_filename)\n",
    "            tifffile.imwrite(new_path, cropped_img)\n",
    "        print('Successfully rotated stack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09092eb-67da-44ce-83f1-e665ddec9f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_clear_image(image):\n",
    "    laplacian_image = filters.laplace(image)\n",
    "    blur_score = np.var(laplacian_image)\n",
    "    if blur_score >= 0:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806bd00-3adc-4029-b425-de63d9b940ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def napari_ready_format_drift_correct(root_dir, experiment_name, c = 0):\n",
    "    \"\"\" \n",
    "    Arg\n",
    "    root_dir: parent directory containing multiple 'Pos#' directories, \n",
    "    each containing tif files of single timepoints and channels of the given position. \n",
    "    File name is default from the Covert lab microscope.\n",
    "    experiment_name: unique id to label output files\n",
    "    c = int representing phase channel index\n",
    "    output: drift corrected files across multiple positions and timepoints. Found within\n",
    "    'cyx_files_for_mm3' directory\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    hyperstacked_path = os.path.join(root_dir, 'hyperstacked')\n",
    "    drift_corrected_path = os.path.join(hyperstacked_path, 'drift_corrected')\n",
    "    output_dir_path = os.path.join(drift_corrected_path, 'cyx_files_for_mm3')\n",
    "\n",
    "    time_dict = hyperstack_tif_tcyx(root_dir, experiment_name)\n",
    "    \n",
    "    drift_correction_napari(hyperstacked_path)\n",
    "    \n",
    "    unstack_tcyx_to_cyx(drift_corrected_path, time_dict)\n",
    "    \n",
    "    return output_dir_path\n",
    "\n",
    "def hyperstack_tif_tcyx(root_dir, experiment_name, c = 0):\n",
    "    \n",
    "    \"\"\"Renames TIFF files without deleting originals.\n",
    "    Args:\n",
    "    input_dir: parent directory.\n",
    "    experiment_name: The desired experiment name.\n",
    "    \"\"\"\n",
    "    root = Path(root_dir)\n",
    "    input_dirs = [str(path) for path in root.glob('**//Pos*') if path.is_dir()]\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir_path = os.path.join(root_dir, 'renamed')\n",
    "    os.makedirs(output_dir_path, exist_ok=True)\n",
    "    stacked_path = os.path.join(root_dir, 'stacked')\n",
    "    os.makedirs(stacked_path, exist_ok=True)\n",
    "    hyperstacked_path = os.path.join(root_dir, 'hyperstacked')\n",
    "    os.makedirs(hyperstacked_path, exist_ok=True)\n",
    "\n",
    "    time_clear_dict = {}\n",
    "\n",
    "    file_groups = org_by_timepoint(input_dirs)\n",
    "    for position, time in sorted(file_groups.items()):\n",
    "        time_clear_dict[position] ={}\n",
    "        time_stacked_image_data = []\n",
    "        for time, channels in sorted(time.items()):\n",
    "            image_data = []\n",
    "            for channel, image_path in sorted(channels.items()):\n",
    "                new_filename = f'{experiment_name}_t{time:04.0f}xy{position}c{channel}.tif'\n",
    "                new_path = os.path.join(output_dir_path, new_filename)\n",
    "                try:\n",
    "                    # Copy the file to the new path\n",
    "                    shutil.copy(str(image_path), str(new_path))\n",
    "                    channel_image = tifffile.TiffFile(new_path).asarray() \n",
    "                    image_data.append(channel_image)\n",
    "                    \n",
    "                except OSError as e:\n",
    "                    print(f'Error copying file: {e}')\n",
    "            stacked_image = np.stack(image_data, axis=0)  # Assuming channels are the first dimension\n",
    "            output_stacked_file = Path(stacked_path) / f\"{experiment_name}_t{time:04.0f}xy{position}.tif\"\n",
    "            tifffile.imwrite(str(output_stacked_file), stacked_image)\n",
    "            phase_image = stacked_image[c, :, :]\n",
    "            if detect_clear_image(phase_image): # only time stack clear images\n",
    "                time_stacked_image_data.append(stacked_image) \n",
    "                time_clear_dict[position][time] = 'clear'\n",
    "            else:\n",
    "                time_clear_dict[position][time] = 'blurry'\n",
    "                print('blurry')\n",
    "        hyperstacked_image = np.stack(time_stacked_image_data, axis=0)  # time as the first dimension\n",
    "        output_hyperstacked_file = Path(hyperstacked_path) / f\"{experiment_name}_xy{position}.tif\"\n",
    "        tifffile.imwrite(str(output_hyperstacked_file), hyperstacked_image)\n",
    "        \n",
    "    return time_clear_dict\n",
    "\n",
    "def drift_correction_napari(hyperstacked_path):\n",
    "    output_dir_path = os.path.join(hyperstacked_path, 'drift_corrected')\n",
    "    os.makedirs(output_dir_path, exist_ok=True)\n",
    "    \n",
    "    for filename in os.listdir(hyperstacked_path):\n",
    "        if filename.endswith('.tif') or filename.endswith('.tiff'):\n",
    "            if re.match(r'(.*)_xy(\\d+)\\.' ,filename):\n",
    "                match = re.match(r'(.*)_xy(\\d+)\\.' ,filename)\n",
    "                experiment, position = match.groups()\n",
    "                img_path = os.path.join(hyperstacked_path, filename)\n",
    "                hyperstacked_img = tifffile.imread(img_path)\n",
    "                # multi-channel 2D-movie\n",
    "                cd = CorrectDrift(hyperstacked_img, \"tcyx\")\n",
    "                # estimate drift table\n",
    "                drifts = cd.estimate_drift(t0=0, channel=0)\n",
    "                # correct drift\n",
    "                img_cor = cd.apply_drifts(drifts)\n",
    "                img_cor_file = Path(output_dir_path) / f\"drift_cor_{experiment}_xy{position}.tif\"\n",
    "                tifffile.imwrite(str(img_cor_file), img_cor)\n",
    "\n",
    "def org_by_timepoint(input_dirs):\n",
    "    \n",
    "    \"\"\"Group files by time and channel id, it does not take into account the z axis\n",
    "    Reads in files in the format exported by the Covert lab scope, \n",
    "    which is as follows: 'img_channel(\\d+)_position(\\d+)_time(\\d+)_z(\\d+)\\.'\n",
    "\n",
    "    Returns a dictionary in the following format:\n",
    "    dict[time_frame] = {channel_id : '/path/to/tif/file'}\n",
    "    \"\"\"\n",
    "\n",
    "    time = 'hyperstacked'\n",
    "    channel = 'stacked'\n",
    "    position = '0'\n",
    "    \n",
    "    file_groups = {}\n",
    "    \n",
    "    for input_dir in input_dirs:\n",
    "        for filename in os.listdir(input_dir):\n",
    "            if filename.endswith('.tif') or filename.endswith('.tiff'):\n",
    "                match = re.match(r'img_channel(\\d+)_position(\\d+)_time(\\d+)_z(\\d+)\\.' ,filename)\n",
    "                if match:\n",
    "                  channel, position, time, z = match.groups()\n",
    "                  time = int(time)\n",
    "                elif re.match(r'(.*)_t(\\d+)xy(\\d+)\\.',filename):\n",
    "                    match = re.match(r'(.*)_t(\\d+)xy(\\d+)\\.',filename)\n",
    "                    experiment, time, position = match.groups()\n",
    "                    time = int(time)\n",
    "                else:\n",
    "                    match = re.match(r'(.*)_xy(\\d+)\\.' ,filename)\n",
    "                    if match:\n",
    "                        experiment, position = match.groups()\n",
    "                path = os.path.join(input_dir, filename)\n",
    "                if position not in file_groups:\n",
    "                  file_groups[position] = {}\n",
    "                if time not in file_groups[position]:\n",
    "                  file_groups[position][time] = {}\n",
    "                if channel not in file_groups[position][time]:\n",
    "                  file_groups[position][time][channel] = path\n",
    "    \n",
    "    return file_groups\n",
    "\n",
    "def unstack_tcyx_to_cyx(path_to_hyperstacked, time_clear_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    input_dir: directory where movies are hyperstacked as tcyx\n",
    "    output_dir: The output directory for TIFF files stacked as cyx\n",
    "    \"\"\"\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir_path = os.path.join(path_to_hyperstacked, 'cyx_files_for_mm3')\n",
    "    os.makedirs(output_dir_path, exist_ok=True)\n",
    "    \n",
    "\n",
    "    file_groups = org_by_timepoint([path_to_hyperstacked])\n",
    "    for position, time in sorted(file_groups.items()):\n",
    "        for time, channels in sorted(time.items()):\n",
    "            for channel, image_path in sorted(channels.items()):\n",
    "                filename = os.path.basename(image_path)\n",
    "                match = re.match(r'(.*)_xy(\\d+)\\.' ,filename)\n",
    "                if match:\n",
    "                    experiment, position = match.groups()\n",
    "                    hyperstacked_img = tifffile.imread(image_path)\n",
    "                    real_times = [key for key, val in time_clear_dict[position].items() if val == 'clear']\n",
    "                    index_times = [i for i in range(0, hyperstacked_img.shape[0], 1)]\n",
    "                    index_to_real_time = dict(zip(index_times, real_times))\n",
    "    \n",
    "                    for index in range(hyperstacked_img.shape[0]):\n",
    "                        cyx_image = hyperstacked_img[index, :, :, :]\n",
    "                        real_time = index_to_real_time[index]\n",
    "                        output_cyx_file = Path(output_dir_path) / f\"{experiment}_t{real_time:04.0f}xy{position}.tif\"\n",
    "                        tifffile.imwrite(str(output_cyx_file), cyx_image)\n",
    "                        \n",
    "\n",
    "def plot_lines_across_FOVs(path_to_stack, c = 0):\n",
    "    \n",
    "    \"\"\"Args:\n",
    "    path_to_stack: Path to stack of cyx format files, in string format\n",
    "    c: Phase channel index in integer format, default = 0\n",
    "    Output is a series of plotted images with identified \n",
    "    horizontal or vertical lines across FOVs/positions\n",
    "    \"\"\"\n",
    "    file_groups = org_by_timepoint([path_to_stack])\n",
    "\n",
    "    for position in file_groups.keys():\n",
    "        earliest_timepoint = min(file_groups[position].keys())\n",
    "        first_file_path = file_groups[position][earliest_timepoint]['stacked']\n",
    "        ref_img = tifffile.imread(first_file_path)\n",
    "        ref_phase_img = ref_img[c, :, :]\n",
    "        horizontal_lines, vertical_lines = id_lines(ref_phase_img)\n",
    "        print('Lines identified in FOV ' + position)\n",
    "        print('Horizontal lines')\n",
    "        plot_lines(ref_phase_img, horizontal_lines)\n",
    "\n",
    "def calculate_line_angle(x1, y1, x2, y2):\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    angle = np.arctan2(dy, dx) * 180 / np.pi\n",
    "    return angle\n",
    "\n",
    "def find_lines(img):\n",
    "    normalized_img = (img / img.max() * 255).astype(np.uint8)\n",
    "    edges = cv2.Canny(normalized_img, 50, 150)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)\n",
    "    return lines\n",
    "    \n",
    "def id_lines(img):\n",
    "    lines = find_lines(img)\n",
    "    h_lines = []\n",
    "    v_lines = []\n",
    "    count = 0\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            angle = calculate_line_angle(x1, y1, x2, y2)\n",
    "            if abs(angle) < 30:  # Adjust threshold as needed\n",
    "                h_lines.append(line)\n",
    "                count+= 1\n",
    "            elif 60 <= abs(angle) <= 120:  # Adjust threshold as needed\n",
    "                v_lines.append(line)\n",
    "                count+= 1\n",
    "            if count >= 50:\n",
    "                break\n",
    "    return h_lines, v_lines\n",
    "\n",
    "\n",
    "def calculate_rotation_angle(img, lines):\n",
    "    \"\"\"calculate rotation angle based on phase image\"\"\"\n",
    "    angles = []\n",
    "    for line in lines:\n",
    "        # Calculate angle of the line\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        angle = calculate_line_angle(x1, y1, x2, y2)\n",
    "        angles.append(abs(angle))\n",
    "    average_angle = sum(angles) / len(angles)\n",
    "    return average_angle\n",
    "\n",
    "def plot_lines(original_img, lines):\n",
    "    plt.figure()\n",
    "    plt.imshow(original_img, cmap='gray')\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            plt.plot([x1, x2], [y1, y2], color='green', linewidth=2) \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def apply_image_rotation(image_stack, rotation_angle):\n",
    "    \"\"\"Applies rotation to an image stacked as cyx.\n",
    "\n",
    "    Args:\n",
    "        image: image in Grey or BGR format for OpenCV \n",
    "        rotation_angle: The rotation angle in degrees.\n",
    "\n",
    "    Returns:\n",
    "        Rotated image in BGR format.\n",
    "    \"\"\"\n",
    "    rotated_stack = np.zeros_like(image_stack)\n",
    "    h = None\n",
    "    w = None\n",
    "    if image_stack.ndim == 3:\n",
    "        h, w = image_stack.shape[1:]\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n",
    "        for i in range(image_stack.shape[0]):\n",
    "            rotated_stack[i] = cv2.warpAffine(image_stack[i], M, (w, h))\n",
    "    \n",
    "    elif image_stack.ndim == 2:\n",
    "        h, w = image_stack.shape\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n",
    "        rotated_stack = cv2.warpAffine(image_stack, M, (w, h))\n",
    "\n",
    "    return rotated_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb21069-306f-46a6-9db5-0611f0655470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a464a21-9712-4030-bff0-55666f4ef913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
